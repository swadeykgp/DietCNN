{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dd96eb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-31T09:34:58.716162Z",
     "start_time": "2022-10-31T09:34:58.105354Z"
    }
   },
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.prune as prune\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np\n",
    "import warnings\n",
    "from vgg_sym import *\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb5d7b58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-31T09:35:05.940668Z",
     "start_time": "2022-10-31T09:35:05.905697Z"
    }
   },
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def print_size_of_model(model):\n",
    "    \"\"\" Print the size of the model.\n",
    "    \n",
    "    Args:\n",
    "        model: model whose size needs to be determined\n",
    "\n",
    "    \"\"\"\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size of the model(MB):', round(os.path.getsize('temp.p')/(1024*1024),3))\n",
    "    os.remove('temp.p')\n",
    "    \n",
    "\n",
    "# Routines for Quantization    \n",
    "    \n",
    "from collections import namedtuple\n",
    "QTensor = namedtuple('QTensor', ['tensor', 'scale', 'zero_point'])\n",
    "nb = 8\n",
    "def calcScaleZeroPoint(min_val, max_val,num_bits=nb):\n",
    "  # Calc Scale and zero point of next \n",
    "  qmin = 0.\n",
    "  qmax = 2.**num_bits - 1.\n",
    "\n",
    "  scale = (max_val - min_val) / (qmax - qmin)\n",
    "\n",
    "  initial_zero_point = qmin - min_val / scale\n",
    "  \n",
    "  zero_point = 0\n",
    "  if initial_zero_point < qmin:\n",
    "      zero_point = qmin\n",
    "  elif initial_zero_point > qmax:\n",
    "      zero_point = qmax\n",
    "  else:\n",
    "      zero_point = initial_zero_point\n",
    "\n",
    "  zero_point = int(zero_point)\n",
    "\n",
    "  return scale, zero_point\n",
    "\n",
    "def quantize_tensor(x, num_bits=nb, min_val=None, max_val=None):\n",
    "    \n",
    "    if not min_val and not max_val: \n",
    "      min_val, max_val = x.min(), x.max()\n",
    "\n",
    "    qmin = 0.\n",
    "    qmax = 2.**num_bits - 1.\n",
    "\n",
    "    scale, zero_point = calcScaleZeroPoint(min_val, max_val, num_bits)\n",
    "    q_x = zero_point + x / scale\n",
    "    q_x.clamp_(qmin, qmax).round_()\n",
    "    q_x = q_x.round().byte()\n",
    "    \n",
    "    return QTensor(tensor=q_x, scale=scale, zero_point=zero_point)\n",
    "\n",
    "def dequantize_tensor(q_x):\n",
    "    return q_x.scale * (q_x.tensor.float() - q_x.zero_point)\n",
    "\n",
    "def calcScaleZeroPoint(min_val, max_val,num_bits=nb):\n",
    "  # Calc Scale and zero point of next \n",
    "  qmin = 0.\n",
    "  qmax = 2.**num_bits - 1.\n",
    "\n",
    "  scale_next = (max_val - min_val) / (qmax - qmin)\n",
    "\n",
    "  initial_zero_point = qmin - min_val / scale_next\n",
    "  \n",
    "  zero_point_next = 0\n",
    "  if initial_zero_point < qmin:\n",
    "      zero_point_next = qmin\n",
    "  elif initial_zero_point > qmax:\n",
    "      zero_point_next = qmax\n",
    "  else:\n",
    "      zero_point_next = initial_zero_point\n",
    "\n",
    "  zero_point_next = int(zero_point_next)\n",
    "\n",
    "  return scale_next, zero_point_next\n",
    "  \n",
    "def quantizeLayer(x, layer, stat, scale_x, zp_x, num_bits=nb):\n",
    "  # for both conv and linear layers\n",
    "  W = layer.weight.data\n",
    "  B = layer.bias.data\n",
    "\n",
    "  # scale_x = x.scale\n",
    "  # zp_x = x.zero_point\n",
    "  w = quantize_tensor(layer.weight.data,num_bits) \n",
    "  b = quantize_tensor(layer.bias.data,num_bits)\n",
    "\n",
    "  layer.weight.data = w.tensor.float()\n",
    "  layer.bias.data = b.tensor.float()\n",
    "\n",
    "  ####################################################################\n",
    "  # This is Quantisation !!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "  scale_w = w.scale\n",
    "  zp_w = w.zero_point\n",
    "  \n",
    "  scale_b = b.scale\n",
    "  zp_b = b.zero_point\n",
    "  \n",
    "\n",
    "  scale_next, zero_point_next = calcScaleZeroPoint(min_val=stat['min'], max_val=stat['max'])\n",
    "\n",
    "  # Perparing input by shifting\n",
    "  X = x.float() - zp_x\n",
    "  layer.weight.data = (scale_x * scale_w/scale_next)*(layer.weight.data - zp_w)\n",
    "  layer.bias.data = (scale_b/scale_next)*(layer.bias.data + zp_b)\n",
    "\n",
    "  # All int\n",
    "\n",
    "  #x = (layer(X)/ scale_next) + zero_point_next \n",
    "  x = layer(X) + zero_point_next   \n",
    "  \n",
    "  # Perform relu too\n",
    "  x = F.relu(x)\n",
    "    \n",
    "    \n",
    "  # Reset\n",
    "  layer.weight.data = W\n",
    "  layer.bias.data = B\n",
    "  \n",
    "  return x, scale_next, zero_point_next\n",
    "\n",
    "\n",
    "def quantForward(model, x, stats):\n",
    "  #print(x.shape)\n",
    "  # Quantise before inputting into incoming layers\n",
    "  x = quantize_tensor(x, min_val=stats['conv1']['min'], max_val=stats['conv1']['max'])\n",
    "  #print(model.features[0].weight.data.shape)\n",
    "\n",
    "  x, scale_next, zero_point_next = quantizeLayer(x.tensor, model.features[0], stats['conv2'], x.scale, x.zero_point)\n",
    "  #x = model.features[1](x)\n",
    "  x, scale_next, zero_point_next = quantizeLayer(x, model.features[2], stats['conv3'], scale_next, zero_point_next)\n",
    "  #x = model.features[3](x)\n",
    "  x, scale_next, zero_point_next = quantizeLayer(x, model.features[4], stats['conv4'], scale_next, zero_point_next)\n",
    "  #x = model.features[5](x)\n",
    "  x, scale_next, zero_point_next = quantizeLayer(x, model.features[6], stats['conv5'], scale_next, zero_point_next)\n",
    "  #x = model.features[7](x)\n",
    "  x, scale_next, zero_point_next = quantizeLayer(x, model.features[8], stats['conv6'], scale_next, zero_point_next)\n",
    "  #x = model.features[9](x)\n",
    "  x, scale_next, zero_point_next = quantizeLayer(x, model.features[10], stats['conv7'], scale_next, zero_point_next)\n",
    "  #x = model.features[11](x)\n",
    "  x, scale_next, zero_point_next = quantizeLayer(x, model.features[12], stats['conv8'], scale_next, zero_point_next)\n",
    "  #x = model.features[13](x)\n",
    "  x, scale_next, zero_point_next = quantizeLayer(x, model.features[14], stats['fc'], scale_next, zero_point_next)\n",
    "  #x = model.features[15](x)\n",
    "    \n",
    "  \n",
    "  #x = x.view(x.size(0), -1)  \n",
    "  x = x.view(-1, 512)   \n",
    "  \n",
    "  \n",
    "  # Back to dequant for final layer\n",
    "  x = dequantize_tensor(QTensor(tensor=x, scale=scale_next, zero_point=zero_point_next))\n",
    "   \n",
    "  x = model.classifier(x)\n",
    "\n",
    "  return x\n",
    "\n",
    "\n",
    "# Get Min and max of x tensor, and stores it\n",
    "def updateStats(x, stats, key):\n",
    "  max_val, _ = torch.max(x, dim=1)\n",
    "  min_val, _ = torch.min(x, dim=1)\n",
    "  \n",
    "  \n",
    "  if key not in stats:\n",
    "    stats[key] = {\"max\": max_val.sum(), \"min\": min_val.sum(), \"total\": 1}\n",
    "  else:\n",
    "    stats[key]['max'] += max_val.sum().item()\n",
    "    stats[key]['min'] += min_val.sum().item()\n",
    "    stats[key]['total'] += 1\n",
    "  \n",
    "  return stats\n",
    "\n",
    "# Reworked Forward Pass to access activation Stats through updateStats function\n",
    "def gatherActivationStats(model, x, stats):\n",
    "\n",
    "  stats = updateStats(x.clone().view(x.shape[0], -1), stats, 'conv1')\n",
    "  x = model.features[1](model.features[0](x))\n",
    "  stats = updateStats(x.clone().view(x.shape[0], -1), stats, 'conv2')\n",
    "  x =  model.features[3](model.features[2](x))\n",
    "  stats = updateStats(x.clone().view(x.shape[0], -1), stats, 'conv3')\n",
    "  x = model.features[5](model.features[4](x))\n",
    "  stats = updateStats(x.clone().view(x.shape[0], -1), stats, 'conv4')\n",
    "  x = model.features[7](model.features[6](x))\n",
    "  stats = updateStats(x.clone().view(x.shape[0], -1), stats, 'conv5')\n",
    "  x = model.features[9](model.features[8](x))\n",
    "  stats = updateStats(x.clone().view(x.shape[0], -1), stats, 'conv6')\n",
    "  x = model.features[11](model.features[10](x))\n",
    "  stats = updateStats(x.clone().view(x.shape[0], -1), stats, 'conv7')\n",
    "  x = model.features[13](model.features[12](x))\n",
    "  stats = updateStats(x.clone().view(x.shape[0], -1), stats, 'conv8')\n",
    "  x = model.features[15](model.features[14](x))\n",
    "\n",
    "  #x = x.view(x.size(0), -1)  \n",
    "  x = x.view(-1, 512) \n",
    "  \n",
    "  stats = updateStats(x, stats, 'fc')\n",
    "\n",
    "  x = model.classifier(x)\n",
    "\n",
    "  return stats\n",
    "\n",
    "# Entry function to get stats of all functions.\n",
    "def gatherStats(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    stats = {}\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            stats = gatherActivationStats(model, data, stats)\n",
    "    \n",
    "    final_stats = {}\n",
    "    for key, value in stats.items():\n",
    "      final_stats[key] = { \"max\" : value[\"max\"] / value[\"total\"], \"min\" : value[\"min\"] / value[\"total\"] }\n",
    "    return final_stats\n",
    "\n",
    "# Routines for performance testing\n",
    "\n",
    "def test(model, device, test_loader, train_loader, batch_size, quantize=False, fbgemm=False, stats=None):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(model)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        st = time.time()\n",
    "        for data in test_loader:\n",
    "            X, y = data\n",
    "            #st = time.time()\n",
    "            # Testing with qauntization if quantize=True\n",
    "            if quantize:\n",
    "                output = quantForward(model, X, stats)\n",
    "            else:    \n",
    "                output = model.forward(X)\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == y[idx]:\n",
    "                #if True:\n",
    "                    correct += 1\n",
    "            total += batch_size\n",
    "        et = time.time()    \n",
    "    acc = round(correct/total, 4)\n",
    "    print(\"========================================= PERFORMANCE =============================================\")\n",
    "    print_size_of_model(model)\n",
    "    print(\"PyTorch optimized model test accuracy :{}% \".format(100*round(correct/total, 2)))\n",
    "    print('Elapsed time = {:0.4f} milliseconds'.format((et - st) * 1000))\n",
    "    print(\"====================================================================================================\")\n",
    "\n",
    "    \n",
    "    \n",
    "# Routines related to pruning     \n",
    "\n",
    "def check_sparsity(model):\n",
    "    print(\n",
    "        \"Sparsity in conv1.weight: {:.2f}%\".format(\n",
    "            100. * float(torch.sum(model.features[0].weight == 0))\n",
    "            / float(model.features[0].weight.nelement())\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Sparsity in conv2.weight: {:.2f}%\".format(\n",
    "            100. * float(torch.sum(model.features[2].weight == 0))\n",
    "            / float(model.features[2].weight.nelement())\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Sparsity in conv3.weight: {:.2f}%\".format(\n",
    "            100. * float(torch.sum(model.features[4].weight == 0))\n",
    "            / float(model.features[4].weight.nelement())\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Sparsity in conv4.weight: {:.2f}%\".format(\n",
    "            100. * float(torch.sum(model.features[6].weight == 0))\n",
    "            / float(model.features[6].weight.nelement())\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Sparsity in conv5.weight: {:.2f}%\".format(\n",
    "            100. * float(torch.sum(model.features[8].weight == 0))\n",
    "            / float(model.features[8].weight.nelement())\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Sparsity in conv6.weight: {:.2f}%\".format(\n",
    "            100. * float(torch.sum(model.features[10].weight == 0))\n",
    "            / float(model.features[10].weight.nelement())\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Sparsity in conv7.weight: {:.2f}%\".format(\n",
    "            100. * float(torch.sum(model.features[12].weight == 0))\n",
    "            / float(model.features[12].weight.nelement())\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Sparsity in conv8.weight: {:.2f}%\".format(\n",
    "            100. * float(torch.sum(model.features[14].weight == 0))\n",
    "            / float(model.features[14].weight.nelement())\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Sparsity in fc1.weight: {:.2f}%\".format(\n",
    "            100. * float(torch.sum(model.classifier[0].weight == 0))\n",
    "            / float(model.classifier[0].weight.nelement())\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Global sparsity: {:.2f}%\".format(\n",
    "            100. * float(\n",
    "                torch.sum(model.features[0].weight == 0)\n",
    "                + torch.sum(model.features[2].weight == 0)\n",
    "                + torch.sum(model.features[4].weight == 0)\n",
    "                + torch.sum(model.features[6].weight == 0)\n",
    "                + torch.sum(model.features[8].weight == 0)\n",
    "                + torch.sum(model.features[10].weight == 0)\n",
    "                + torch.sum(model.features[12].weight == 0)\n",
    "                + torch.sum(model.features[14].weight == 0)\n",
    "                + torch.sum(model.classifier[0].weight == 0)\n",
    "            )\n",
    "            / float(\n",
    "                model.features[0].weight.nelement()\n",
    "                + model.features[2].weight.nelement()\n",
    "                + model.features[4].weight.nelement()\n",
    "                + model.features[6].weight.nelement()\n",
    "                + model.features[8].weight.nelement()\n",
    "                + model.features[10].weight.nelement()\n",
    "                + model.features[12].weight.nelement()\n",
    "                + model.features[14].weight.nelement()\n",
    "                + model.classifier[0].weight.nelement()\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    \n",
    "def check_sparsity_unst(model):\n",
    "    print(\n",
    "        \"Sparsity in conv1.weight: {:.2f}%\".format(\n",
    "            100. * float(torch.sum(model.features[0].weight == 0))\n",
    "            / float(model.features[0].weight.nelement())\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Sparsity in conv2.weight: {:.2f}%\".format(\n",
    "            100. * float(torch.sum(model.features[2].weight == 0))\n",
    "            / float(model.features[2].weight.nelement())\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Sparsity in conv3.weight: {:.2f}%\".format(\n",
    "            100. * float(torch.sum(model.features[4].weight == 0))\n",
    "            / float(model.features[4].weight.nelement())\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Sparsity in conv4.weight: {:.2f}%\".format(\n",
    "            100. * float(torch.sum(model.features[6].weight == 0))\n",
    "            / float(model.features[6].weight.nelement())\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Sparsity in conv5.weight: {:.2f}%\".format(\n",
    "            100. * float(torch.sum(model.features[8].weight == 0))\n",
    "            / float(model.features[8].weight.nelement())\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Sparsity in conv6.weight: {:.2f}%\".format(\n",
    "            100. * float(torch.sum(model.features[10].weight == 0))\n",
    "            / float(model.features[10].weight.nelement())\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Sparsity in conv7.weight: {:.2f}%\".format(\n",
    "            100. * float(torch.sum(model.features[12].weight == 0))\n",
    "            / float(model.features[12].weight.nelement())\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Sparsity in conv8.weight: {:.2f}%\".format(\n",
    "            100. * float(torch.sum(model.features[14].weight == 0))\n",
    "            / float(model.features[14].weight.nelement())\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Sparsity in fc1.weight: {:.2f}%\".format(\n",
    "            100. * float(torch.sum(model.classifier.weight == 0))\n",
    "            / float(model.classifier.weight.nelement())\n",
    "        )\n",
    "    )\n",
    "    print(\n",
    "        \"Global sparsity: {:.2f}%\".format(\n",
    "            100. * float(\n",
    "                torch.sum(model.features[0].weight == 0)\n",
    "                + torch.sum(model.features[2].weight == 0)\n",
    "                + torch.sum(model.features[4].weight == 0)\n",
    "                + torch.sum(model.features[6].weight == 0)\n",
    "                + torch.sum(model.features[8].weight == 0)\n",
    "                + torch.sum(model.features[10].weight == 0)\n",
    "                + torch.sum(model.features[12].weight == 0)\n",
    "                + torch.sum(model.features[14].weight == 0)\n",
    "                + torch.sum(model.classifier.weight == 0)\n",
    "            )\n",
    "            / float(\n",
    "                model.features[0].weight.nelement()\n",
    "                + model.features[2].weight.nelement()\n",
    "                + model.features[4].weight.nelement()\n",
    "                + model.features[6].weight.nelement()\n",
    "                + model.features[8].weight.nelement()\n",
    "                + model.features[10].weight.nelement()\n",
    "                + model.features[12].weight.nelement()\n",
    "                + model.features[14].weight.nelement()\n",
    "                + model.classifier.weight.nelement()\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    \n",
    "# Use this knowledge to prune the network locally\n",
    "def local_prune_and_test(sp, net, structured=True, quantize=True, stats=None):\n",
    "    # prune the model layerwise\n",
    "    prune.l1_unstructured(net.features[0], name=\"weight\", amount=sp[0])\n",
    "    prune.l1_unstructured(net.features[2], name=\"weight\", amount=sp[1])\n",
    "    prune.l1_unstructured(net.features[4], name=\"weight\", amount=sp[2])\n",
    "    prune.l1_unstructured(net.features[6], name=\"weight\", amount=sp[3])\n",
    "    prune.l1_unstructured(net.features[8], name=\"weight\", amount=sp[4])\n",
    "    prune.l1_unstructured(net.features[10], name=\"weight\", amount=sp[5])\n",
    "    prune.l1_unstructured(net.features[12], name=\"weight\", amount=sp[6])\n",
    "    prune.l1_unstructured(net.features[14], name=\"weight\", amount=sp[7])\n",
    "    prune.l1_unstructured(net.classifier[0], name=\"weight\", amount=sp[8])\n",
    "\n",
    "    # Remove the layerwise data structures for pruning\n",
    "    net.features[0] = prune.remove(net.features[0], name='weight')\n",
    "    net.features[2] = prune.remove(net.features[2], name='weight')\n",
    "    net.features[4] = prune.remove(net.features[4], name='weight')\n",
    "    net.features[6] = prune.remove(net.features[6], name='weight')\n",
    "    net.features[8] = prune.remove(net.features[8], name='weight')\n",
    "    net.features[10] = prune.remove(net.features[10], name='weight')\n",
    "    net.features[12] = prune.remove(net.features[12], name='weight')\n",
    "    net.features[14] = prune.remove(net.features[14], name='weight')\n",
    "    net.classifier = prune.remove(net.classifier[0], name='weight')\n",
    "\n",
    "    # Check sparsity\n",
    "    if structured:\n",
    "        check_sparsity(net)\n",
    "    else:\n",
    "        check_sparsity_unst(net)\n",
    "\n",
    "    # test the baseline accuracy this is a trial & error phase\n",
    "    test(model=net, device=device, test_loader=testloader, train_loader=trainloader, batch_size=bs, quantize=quantize, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e88be65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-31T09:35:18.357421Z",
     "start_time": "2022-10-31T09:35:17.680315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 32, 32])\n",
      "torch.Size([16])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2400x1600 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "bs= 16 \n",
    "transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='../../../formal_pruning/dataset', train=True, download=False, transform=transform_test)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=False)\n",
    "testset = torchvision.datasets.CIFAR10(root='../../../formal_pruning/dataset', train=False, download=False, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=bs, shuffle=False)\n",
    "num_classes = 10\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "images, labels = next(iter(testloader))\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "figure = plt.figure(figsize = (24,16))\n",
    "num_of_images = 8\n",
    "for index in range(1, num_of_images + 1):\n",
    "    plt.subplot(6, 10, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[index].permute(1,2,0).numpy().squeeze().astype('uint8'), cmap='cool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "807daf78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-31T09:35:42.685567Z",
     "start_time": "2022-10-31T09:35:42.638139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "pretrained_model = \"./cifar_vgg_sym_v3.pt\"\n",
    "net = VGG('VGG11')\n",
    "sd = torch.load(pretrained_model, map_location=torch.device('cpu'))\n",
    "net.load_state_dict(sd['net'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0d3304a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-31T09:36:02.657251Z",
     "start_time": "2022-10-31T09:35:45.695185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "========================================= PERFORMANCE =============================================\n",
      "Size of the model(MB): 35.198\n",
      "PyTorch optimized model test accuracy :90.0% \n",
      "Elapsed time = 16920.1539 milliseconds\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Baseline performance - unquantized model\n",
    "device = 'cpu'\n",
    "test(model=net, device=device, test_loader=testloader, train_loader=trainloader, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39bb0370",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-31T09:37:31.222983Z",
     "start_time": "2022-10-31T09:36:52.424912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv1': {'max': tensor(38.0929), 'min': tensor(-34.3413)}, 'conv2': {'max': tensor(102.6974), 'min': tensor(0.)}, 'conv3': {'max': tensor(106.0568), 'min': tensor(0.)}, 'conv4': {'max': tensor(71.1720), 'min': tensor(0.)}, 'conv5': {'max': tensor(50.4030), 'min': tensor(0.)}, 'conv6': {'max': tensor(23.9288), 'min': tensor(0.)}, 'conv7': {'max': tensor(15.2678), 'min': tensor(0.)}, 'conv8': {'max': tensor(33.0083), 'min': tensor(0.)}, 'fc': {'max': tensor(61.2125), 'min': tensor(0.)}}\n"
     ]
    }
   ],
   "source": [
    "# Quantized model performance\n",
    "import copy\n",
    "netq = copy.deepcopy(net)\n",
    "\n",
    "# one time stats gathering - we will keep this stored for CIFAR for the FPGA implementation\n",
    "#stats = gatherStats(netq, trainloader)\n",
    "stats = gatherStats(netq, testloader)\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "246550c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-31T09:38:31.013791Z",
     "start_time": "2022-10-31T09:37:36.130918Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "========================================= PERFORMANCE =============================================\n",
      "Size of the model(MB): 35.198\n",
      "PyTorch optimized model test accuracy :19.0% \n",
      "Elapsed time = 54792.2206 milliseconds\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Quantized Inference with the normal model\n",
    "test(model=netq, device=device, test_loader=testloader, train_loader=trainloader, batch_size=bs, quantize=True, stats=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b806de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-31T09:12:12.144812Z",
     "start_time": "2022-10-31T09:12:12.085574Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the QAT trained model\n",
    "pretrained_modelqat = \"./cifar_qat.pt\"\n",
    "netqat = VGG('VGG11')\n",
    "sdqat = torch.load(pretrained_modelqat, map_location=torch.device('cpu'))\n",
    "netqat.load_state_dict(sdqat['net'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581a5dc3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-31T09:13:18.185075Z",
     "start_time": "2022-10-31T09:13:04.095390Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Gathering stats for activation quantization\n",
    "stats = gatherStats(netqat, testloader)\n",
    "print(stats)\n",
    "device = 'cpu'\n",
    "# Try inferencing\n",
    "#test(model=netqat, device=device, test_loader=testloader, train_loader=trainloader, batch_size=bs, quantize=True, stats=stats)\n",
    "test_qat(model=netqat, device=device, test_loader=testloader, train_loader=trainloader, batch_size=bs, quantize=True, stats=stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
