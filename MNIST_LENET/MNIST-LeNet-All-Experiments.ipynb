{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28b23d7e",
   "metadata": {},
   "source": [
    "## Section 1: First we try PyTorch Quantization. \n",
    "### This is the best available option as we will see, in terms of accuracy preservation. \n",
    "### However, the FBGEMM backend is not available of FPGA and other embedded systems. In the next section we will implement  Quantization from scratch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89927c12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T06:07:17.257229Z",
     "start_time": "2022-11-03T06:07:16.305754Z"
    }
   },
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.prune as prune\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7ed3f864",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T06:23:19.910511Z",
     "start_time": "2022-11-03T06:23:19.875399Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "bs= 16 \n",
    "transform_test = transforms.Compose([transforms.Resize(32),transforms.ToTensor(),\n",
    "                                          transforms.Normalize((0.1309,), (0.2893,))])\n",
    "\n",
    "trainset = datasets.MNIST(root='../../dataset', train=True, download=True, transform=transform_test)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=bs, shuffle=False)\n",
    "    \n",
    "testset = datasets.MNIST(root='../../dataset', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=bs, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "647be2e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T06:08:19.912307Z",
     "start_time": "2022-11-03T06:08:19.761948Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 32, 32])\n",
      "torch.Size([128])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAA+CAYAAAC2oBgNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy89olMNAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAyVklEQVR4nO29Z3Ob15n//wFR2EAUohBg772IpEh12U6cxCmend1NMrMPkt2XsDM7O/sS9um+iczOZCfxZFM2tn+WY8tqViNFkWIBCYAkSBAkQPRe/g/0P8eULUe0JZJgdH9mNFYcUb5v4L7P+Z6rfC9VqVQqoaCgoKCgoPDaUnHSF6CgoKCgoKBwsihiQEFBQUFB4TVHEQMKCgoKCgqvOYoYUFBQUFBQeM1RxICCgoKCgsJrjiIGFBQUFBQUXnMUMaCgoKCgoPCao4gBBQUFBQWF1xxFDCgoKCgoKLzmKGJAQUFBQUHhNUcRAwoKCgoKCq85muP4j4jxBwf/eXAkQkVFBSqVCkD+U0FBQUFBQeF4OHIxkM1m2djYYGtri1QqRTqdJhAI4PV6yeVy6HQ6ent7aW5upqGhAbvdjsViOerLUlBQUFBQUPj/OVIxEAwG8fl83L17F5fLRSKRIJFIsLu7i9vtlmJgcHCQjo4OBgYGGBkZwWg0otEcS9DilZPNZgkGgwQCAdLpNE1NTZhMJvR6/Ulf2tdSLBZJp9NsbGwQCoWIx+NUV1fT2tqKyWSitrYWtVp90pepoKBwxJRKJYrFIrlcjnw+/0wEV6fTkU6niUQiVFRUUFVVhU6nk/9U+OZks1ny+TwAVVVVJJNJuU/u7+9TXV2NVqtFo9FQWVmJXq8/ss/7yHbcZDLJ+vo6jx8/5saNG7hcLtLpNNlslkgkwt7eHrlcDo1GI6MFhUIBo9FIV1cXer2eiorTV9KQSqXY2Njg8ePHRKNRzp8/j0ajKVsxUCqVyOfzRKNRHj58yNraGnt7exiNRi5fvkxHRwdarZbq6uqTvtTnUiwWyWQyFItFVCoVNTU1L/wZseCVSiUqKipO1XNWKBTIZrPkcjlKpRJVVVVoNJqyEWvi+8jn86jVatRqNVqt9lt9xsVikUKhgFqtPlXf0Wkkn8+Ty+XIZrNks1lisRjpdJpisSj/jMFgIBKJsLGxgUajoa6uDqPRiMVioaGh4QSv/vRRLBbJZrPs7e3Jz9lgMLC/vy8Pk5ubmxiNRqqrq6UQsNlsmEwm+e+1Wu0rS60fmRjwer3cuHGDzz77jE8++YS9vT2KxSI6nY6amhpsNhulUol0Oo3H4yEQCABPH7iRkZFTqzbD4TBzc3P8+c9/JhgMYrVaMZvNOByOk7605yIWb5/Px3vvvcfDhw/Z3NzEarWiUqkolUrU1dWVpRgolUpkMhk2NzdJpVJoNBoGBwdf+HO5XI5MJkM2m6W2thadTndqNpt4PM7u7i6BQIB8Pk9bWxtmsxmDwXDSl0ahUCCVSuHz+YhGo1RXV2M0GrHZbFRWVn6jRatQKJBOp0mlUvI7KhfB87dGoVAgHA4TCoXY399nf38fv99PJBKhUCgAT+u67HY7e3t7LCwsUFFRQX19Pc3NzQwPD2O325V6r0Mi1tytrS0ePXrE/v4+2WwWq9WK3+/H5/Ph9XpZWlqioaGB2tpaampqMJlMtLa20tDQQHNzMz09PVitVnQ63Sv57F+5GBA3+qtf/YrPPvuMxcVF9vf3MZlMmM1m6uvraW1tpa+vj2w2i9/v58MPP2R/fx+fz8fCwgKrq6vYbLZTKQZ2dnYIBALE43FMJhNWq7WsowLJZJJAIMCjR4+4desWOzs7FItFtre3WVxcxOl00tzcjM1mO+nL/Qq5XI7t7W3ee+89dnd3MRqNhxID0WgUn8/H1tYWDoeD7u5uamtry14QFItF5ufn+eSTT7h+/TqJRIKf/vSnXLhwgYmJiRO9/mKxSCAQYHV1lT/+8Y94vV46OzsZGRnhu9/97qEXLBGpcrvd+Hw+dnZ2OHPmDE1NTdTU1JyYIMjlcqTTaaLRKPl8HoPBgNFoLPtn5suIqFg2myUajZJIJIhEIszPzzM3N4fX62V9fR2Px0M8HpchbLVajdVqpVQqEYlESKfTAPT39/Puu+9y4cIFRawdklgsxsbGBn/4wx/43e9+h9/vJ5FIyNS4iP4BuN1u+d6USiVUKhUGg4GmpiZ++ctf8r3vfQ+Hw0FVVdVLC4JXKgbESc3n8/H48WO8Xi/JZBKTycSlS5c4c+YMvb29WCwWrFYruVyOzc1N3G438/PzAGQyGRkCPW2USiWCwSDhcJhsNktHRwfNzc2YzeaTvrSvIOoEtre3efLkCe+//z7RaJRisShD6LlcTv4qFAqoVCr5qxzI5XL4/X42NjaIx+NUVlYe6ucSiQQbGxvMzMyg0WgwmUxUVVWV9cIuhNu9e/e4e/cu8/PzpFIp7t27R2NjI2fOnDnR64/H49y9e5fr169z7do1dDodJpOJXC6HXq8/tBAoFAqEQiF+85vf8OTJE+LxODU1NdTV1Z1IdECsabu7u/h8Pu7cuSPTf5cuXTpUWqqcOBi9uXnzJktLS7jdbvx+P6FQiFgsRiwWI5FIyA0JkFFC+CKlAMjagpPmYKfawTUMnl67Wq0ui/WrVCqxvr7OvXv3uHHjBqurq8TjcUqlEtXV1VitViorK9FqtVRWVsrnvVAosLe3h9/vZ3d3l0QiwW9/+1ucTicVFRU4HI5Dr39fxysXAyIPsr29TTKZRKvV0tXVxZUrVzh//jz9/f3U1NSg0WiIRCKUSiX5v9VqNZWVla8s7HGciJSHz+cjFAoB0NjYiM1mK7sFo1AoEIvF2N7eZmlpiYcPH3L//n0ymcwzf06chPb29tjb26OmpkZ+P+VALpcjEAiws7MD8Ex+869RKBRIJpPs7Oyws7PDD37wA5xOJ1qt9igv96UQodzFxUXcbjeBQACVSkU4HCaRSJyYeD54kr9//z63b9/G5/MxNDSE1WrFarVSVVV1qL+rWCySSqVYXV3l008/xe12YzQayWQyMlx9nBSLRRKJBD6fD5fLxeLiIteuXSMej2M2m5mcnKS6uvpUrVUHxcBf/vIXHj58KOu5vg5Ri3NwcxIYDIYTX9+EYCsUCuRyOcLhMLFYTB4qa2trMZlMVFdXU1VV9dKb5suQyWTwer3Mzc2xsLBAJBJBp9NhNBppaWmhtbVVfqY1NTXy2crn86yurkpREAwGuXv3LnNzcxiNRgwGw0vvm69cDIgvI5/PU1NTg9Vq5Wc/+xn/8A//gM1mk7nnbDYrX66lpSWi0SjNzc3yV7lsOIcln8+ztbXFnTt3WF9fp7Kyku7u7hN98L6OdDrN48eP+fDDD5mbm8PlcrG+vv6VzdTv9/P48WNyuRzBYJCuri4aGxvLolhIiK/19XU2NjYwmUyH/tnq6mrMZjNWq5V79+4Rj8fJZrPfOK99nORyOVwulxSbhUKB9vZ2+vv7aWpqOjEhI4pPRVrQ5/PR2dnJz3/+cy5evEh/f/+h/650Os3Ozg6/+c1vWFxcxGaz8c477zA+Pi7rDo6TTCaDy+Xivffe486dOywsLLC7u0ttbS1bW1skEgkMBsOp6nwSQnh9fZ2PP/4Yv9//V0/2Go2GqqoqmpubaWlpobq6+pkIVFNTE21tbSf23ggh4Pf7icVi7O/v8/nnn/Po0SNCoRD5fJ7e3l4uXbpER0cHTU1NNDY2AifjaRMIBFhZWWFubo7t7W20Wi2dnZ2cOXOGX/ziFzgcDlmjdVAMZDIZZmZm+PWvf82dO3eYnZ0lFovx//7f/wPAZrOh1+vRaDTf+r5e6VOsVqsxGo1MTU3xn//5n2SzWaqrq+no6KChoeEZ5VIoFHC5XHz22WeEQiEZkhIVyKeNQqHA9vY2e3t7aLVaOjo66O/vL0sxEI/HuX79Or/5zW/Y29sjmUw+91S9srKCz+fj888/x2KxcPbsWS5evMjVq1dpamo6gSv/gmAwiMvlYmZmBoCWlpZD1QvAF6ej/f19vF4vkUiETCZTti2UxWKRSCTC73//e5aXl9nf30etVtPW1sbY2BgtLS0ncl2lUolUKoXL5eLevXsyvylC6K2trYcWKel0Gr/fz+zsLL/97W+xWq2cP3+e7373u68kBPpNyWQybG9v8/777/P73/8en89HJBIhl8uhUqm4ffs2dXV1/PznP6exsZHKysqySzMlk0lWVlbY3t6mVCrR29srUzZqtRqNRkNtbS0qlYp8Pv+M14vY/C0WiyxQraur+8pmU1lZicFgOPZ7j8fjbG1t4fV6uXXrFg8ePGB/f59YLEYkEpFpjlKpxOPHj7l27Rp1dXUYDAba2tpobW1lZGSE8+fPY7PZju36U6kU0WiUaDRKOp1meHiYK1eucOXKFc6ePSujL1/uoKmurmZiYkK+92azmevXr/Pw4UP0ej1dXV3Y7faXast/5ZJWtJwMDg5SKpVQq9UyhFFRUSGV3OLiIouLi3i9XjKZDHq9HovFIhVOOS7Kf41sNsvc3BzhcBiz2YzT6cRms5XdqWFzc5O5uTlmZmZkKkfk2AQVFRUyx5ZOp2W6QKSB8vk8v/jFL07sHmKxGE+ePOHu3bt4PB4cDgf9/f309fUd6udTqRTBYJCNjQ3S6TSFQqFsa1QOFnkKIZDJZNBqtdhsNlpbW6mvrz+R60qn04RCIRYXF9nb28NkMtHY2Mjo6Ch2u/3QHSiZTAaPx8PMzAyffvopoVCI8fFxenp6cDqdr6Q46puyu7vLysoKCwsL8tQp8uSFQgGPx8P169dRqVRSkDmdTurr6088uiRqL27cuMHMzAx+v1+eiGtra9Hr9XR3d/N3f/d3MiKWSCRwOBxYLBbq6+tliqeurg69Xo9Op3uu4KmoqDi2NS6TyZBIJPD7/TJd5vF4mJ+fx+12k8lkUKvV6PV6DAYDqVSKSCRCMpkEnnZ6idSa3+8nk8lgNBqpqqo6tj2nUCiQz+dRqVTYbDbGxsYYHx9naGhIttM/r65BpVKh1+vp7OyUXTYPHz6UInplZYXp6Wlqa2vLRwyoVCp0Oh0NDQ2y+lGoHJFGCIVCPHz4kKWlJYLBIMViEYvFQmNjI06n89R5DIgTksgBCRdFg8FQVqIml8vh8XiYnZ1lZWVFqueDD54wERGhKlFFHY/HcbvdspDw7//+76murj6R+wsEAiwsLMhQ2djYGD09PbS2th7q55PJJHt7e2xtbX2l2KjcKJVKxGIx/H4/m5ubxONxisUiWq0Wq9WK3W6nrq7u2K8rn8+zv78vPTVisZg8bfX29spT5IsoFoskk0n5XN69exe1Wk1HRwcdHR2YzWYpTI+LYrEoF1i32y0/cxHZzOfz7O3tMTc3RzweZ39/XxZwmkymE33nhWAPBoN89tlnzM3NkUwmqampoVgsymhAW1sb77zzDmq1mqqqKiKRCPX19ej1etnKVlNTg06nkz4RJ12gGgwG2dnZ4cmTJ9y5cwePx8P29jahUIhkMilrA4RADoVC0kitpqaGRCJBOBwGnhYRi3eora3tufUQR4Ho4CiVStjtdgYGBujt7aWlpeWF74tGo8Fms9Hd3S271fx+P+FwGK/XSywWw263f+trOzJJ97zwYDabJRwO8/jxY373u98xNzdHNBqlsrKSM2fOMD4+Tl9fHzU1NadKDKTTaYLBILOzs4TDYSoqKmQRSDndx+7uLouLi8zOzuLz+b5SlKVWq3E4HLS3t9Pd3Y3BYCCTyRAKhZiZmcHj8bC6ukpFRQWPHz9mYGCAurq6Y73HUqnEgwcPuHPnDsvLyzQ2NnLp0iUGBwexWq0v/PlcLic3MZfL9ZU5GeWGSD8tLCwQDAbJZDJUVlZis9lobGzEaDSeSCoqHo8zMzPDrVu3ZN6yt7eXCxcu0NPTc+j6i2KxyP7+Pk+ePGF+fh6v18vo6CiXL19maGgIg8Fw7CftZDKJy+Xi/v378nk3m80yQrG1tUU8HpeeDyIsXVNTQ0dHx4lEMgS5XI6dnR0++OAD3n//fbLZLA6HQ3Y11dTUUFVVhcPhwGQySXe7VColf19Oa5bg3r17PH78mNXVVRYWFlheXpabqs1mo6uri6GhIQYHB2lsbMRgMLC8vMzs7Cw7Ozs0NDSwvr7O7OysrN5fWFggGo0yODhIXV0dWq32SAVBqVRibm4Oj8dDMpmUXgHNzc0YjcZD/R1VVVXyfnt6eohEIkSjUVZWVohEIi/V2XGsMex0Os3u7i7379/nwYMH7O7uolKp6Ozs5MqVK0xOTtLe3l5Wp+kXUSgUCAaDrK2tsbOzQ6lUktaR5XIfIkf+wQcfcOPGDRYXF0kkEvKkIFI7TU1NTE1NMTU1RU9PD3q9Xlbda7Va9vf3SSaT+P1+fvWrX/HjH/+Y3t7eYwnlHiwUunbtGouLi+Tzec6ePcv4+DhOp/OFn3ehUMDv97OwsCD7qFtbW6mtrX2lTl6vkkKhwObmJo8ePSIejwNPi4WGh4cZHh4+MTOoZDLJ8vIy9+/fZ2lpia6uLpqammhpacFkMr1wQykWi8RiMXZ2drh58yZ37txhe3sbi8XCP//zPzM5OSnrjI6bnZ0d3G63tEwfHx+nt7eXxsZGstksd+7cYXNzk0AgQCKRwO12Szc4h8PBwMDAsUc3ReeDSLf86le/wu12Mzk5yeXLl7lw4QJ2u112dqjV6mcK1A7+vlzI5/Pynn7961/z+PFjNjY2CIfD1NbW0tHRQXt7O5OTkzQ2NtLX10dnZ6c8hFVWVhIOhzEajQwNDdHW1oZarebPf/4zpVJJRhv8fj+pVAqj0Xhka7Yo3Hz48CFer5d0Oo3D4ZCmQt8EsV5PTExIESDShy9zsDk2MZBIJNje3mZtbU2GqIXiHhsbo6+vj6amprI16Pk6SqUS4XCYra0t0uk0JpOp7GYRFAoF4vE49+7dY3Fxke3tbXK5HFqtltraWurr6+nq6qK/v5/JyUnGxsaw2+3odDoymQwmk4nl5WUePXokC6lu3rxJXV0dmUyG6upq7Hb7kavqeDzOwsICLpeLVCqF2WyWJ54XnY5F+HRjY4PFxUV2d3epqalhYGAAs9lclu2sol5gZ2cHj8cji9fq6+vp7u6ms7PzxLpuREuhsB4uFAokEgmCwSCbm5uyFe3LoU8h6hKJBFtbW7hcLj799FOWlpbI5XI0NjZy8eJF6ax2EojTViaTwWKxMDk5ydTUFB0dHSSTSYxGI59//jkzMzNy+Jrw61heXqatre1Yo4Li2d7a2pJRM7fbjd1up6+vj6GhoecWOR583svt2RfPk8/n49NPP5XOqPF4HIPBwMDAgPw1OTmJ0WjEbDZLISpSaTqdjnw+L1sn6+rqyOfzpFIp1Gq1THUex0HG5/Ph9/tlYb3D4TjU2vVlhNBxOp0yAidSnadCDIjq70ePHrG6uko+n8doNNLW1sbZs2fp7OzEYrGcypbC/f19tra2yGaz2O12GhoaDh32OWqECYc4yW1sbLC/v08+n6euro6Ghgba29u5ePEiQ0ND9Pf3y1AnPL0/nU5HV1cXLS0tRCIRfD4fS0tLsq6gq6sLi8XyzCjqV40QNPPz82xublJdXU1DQwONjY2HcqYTytzr9eJyudjf38doNHLmzBnMZnNZRgYKhQKRSAS/3y+fL7VajclkoqWlhcbGxhNrKTxYkV5RUSF71xcXF8nlclitVkwm01d60AuFAvv7+wQCAdxutywE3dvbw26309bWRm9v74l+F/F4/Jm87ujoKBMTE3R1dZFIJKisrCQej7O+vs729jaZTIZIJML29rZc7I8z9SSsm71eLw8ePODBgwdEo1Gmp6cZGRmhp6fnxGsZvini2V9fX+ezzz5jdXWVZDKJTqejpaWFqakphoeH6e3tpa+vT3Y5FItFuflnMhlUKhXxeJy1tTUSiYQsmM5msxgMBux2u2zJOyrxJtZft9tNMBikVCrJYluTyfStxIBWq5VpnlfFsYiBQqHAo0eP+OMf/8hf/vIX3G43Go2Gvr4+3nrrLX7yk59I5XqaECYpIuJRKpUYHR1ldHT00MVsx4EQBKlUSg71ES/V9PQ0ly9f5qc//elzneI0Gg1Go5GRkREuXLhAJpMhEAiQTCa5fv06NTU1TE9P097e/lI9ri9CiK67d+8SDAY5e/YsZ86cobOz81CFaqlUikAgwNzcHEtLS2SzWdrb23n33XdxOBxlJ0LF97WyssLy8jJer5dsNovNZsNut+N0Or+Rt8KrRq1WU1tbi8FgQKvV4vV6icfjPHjwALPZzMDAAG1tbV8paMpms7hcLilMt7e3iUajtLS00NXVxcTExImLsmg0SiqVQqVS0draKo1gRGfUmTNnpBgWz7xWq6WqqkpWcx9niiCfzxMKhbhz546MsrS0tPAv//IvjIyM4HA4yq6r6UUI7/65uTk+/vhjgsGgjEBeuXKFH/3oR9LQSpiOCZfETCYjje+y2Sybm5v86U9/IhwOS2M1lUqF0+nk4sWLMlV4lGJgf3+fTz75hPX1dRmJHRoawm63l82+d+RPiFB4Ho9HVn+WSiWsVivnzp3jJz/5iVyMT3oR+CaI1qonT55w69Ytbt26hdlsZnBwUEY5yhWtVovT6eT73/8+b775JhMTE3/VMraiogKn08nw8DB+v5+1tTVWV1eBL6ZvHWVFvrBODgaDLC4ukslkaGlpYXx8XIqQFyEGrIjQ7sEXshzNhsSiJqZICkZGRhgdHaWtre0Er+6p89z09DSlUonFxUU2NzdlKNTr9TI/P49Wq33uxEKR/hCucaIV+erVq/zwhz88oTv64trm5+dZX19nb28PjUaDx+ORrcLilLezsyMFGjztAxet0cdtbZ3P54lEItLaVpgE1dfXn2gx48sg2usqKiqkDXVFRYVMh3z00UdyvkIwGJSRqlKpxM7ODpubmySTSZkSEB4R8LRjSqSnf/SjH9He3n6kTpLFYpFwOMytW7dIp9N0d3dz7tw5enp6ykqkHfmVpFIp5ubmePDggfQUqKyspLe3V1ZSlqNhx4sQi7XH42F9fZ1IJEJXVxdGo1EWpJUbIkJQXV3NuXPn+O53v0t/fz8Wi+WvvgjiRdPpdOh0OjQajdz4d3d3mZubY3h4+Mi840V+WhgFORwO2dN92M85k8kQDocJh8OyF9lisZSlEIAv8sDb29vStlun09Hb20tXV9eJu0DqdDpZcPrLX/4St9vN7u4uOzs7rKysEAqFZNtac3Oz/DlhyPX555/L6YZ6vZ6mpiZpenPSNDQ0YDKZ0Gg0BINBfD4f29vbVFdXEwwGWV5eliPKhSdHKpViZ2eHjY0NIpGIrNo/DgqFAtFolNXVVTkXZWtri9nZWWkmJHwfyvFZfx6i7a+1tZWWlhYSiYQUPbOzs3IvSafTJJNJKR7EIKVIJPLMASWbzUo3xa6uLi5evMj09DQDAwNHPgBL+D6kUikMBgNOp1MaB5XTvnekYkBEBUT3gN/vB8BsNjM+Pk5XV9epy2UJxGItThAihFtXV1d2G4zIt+fzeUqlEnq9nomJCc6dO3eoz/9gsZjIxYl/H4/H8Xg8L93j+iIOTlvr7OyUuTbhZfGin02n04TDYaLRKBqNBoPBgM1mK6vvSSA+73g8Lms8SqUSlZWVtLW1SWe4k0Sj0WCxWNDr9TidThn5W11dpba2Fo/Hg8lkwul0Mjo6Kn+uurqayclJaQaTTqex2Wy0tbXhcDi+cWX1q0alUtHV1YXT6WRlZQW/34/b7cZkMhEOh/F4PNy/f5+FhQUAnE6ntF/f2tpicXERn89HXV3dsYqBWCyGx+MhGo2Sy+Xwer188sknRCIRenp66O/vl+kCsWl+2elOeIgII6GTfDe0Wi12u53u7m7Gx8cpFApyQI/H45Gb/ME6JTGbQKRCD1JRUUFtbS02m40LFy7ws5/9jN7e3mMrVBXFfbW1tdIfRLg/lgtHKgYCgQCLi4s8fPiQ9fV18vk8VquV6elpfvrTn9LV1VV2udrDIkY1e71egsEgWq2WiYkJnE7niQ/uOIhofbx27Rr7+/sUCgUZejts+6MwYZmfn2d5eRm/3y+VeFNTE2+++eaR1nyI6lmDwUBra6v0II9EItJB7a8h6jqWlpZYXV2lubkZh8NBR0fHkVzvyyK8HR49esTNmzfxer0Ui0VqamqwWCzPLcw7CSoqKqiurpaDVvr7+0mn0/z85z+XbnA6ne6ZaxURNeGE19DQwJtvvskPfvADurq6ymJx7Ovro729nUePHrGyssIf/vAHPvroI7RaLblcjlQqhclkYnx8nH/6p3/io48+Yn5+Hp/Px9zcHPfu3ZMT6I4DsRaJ9wGePvP/93//x/Xr16mvr2dsbIzp6Wnq6+ul42BDQwMWi0W21O3u7qJWq6mrq5NuhSd1chWbd19fH//xH/8hI5AHzcYqKyupqanBYDCQzWYJhUKy8+bLg5csFgv9/f1cuHCBX/ziF7S0tLyUW99hEYdG0XUjzJuOstj623Jkn0Qmk2FpaYlbt27x+PFjUqkUVVVVmEwmuru7aW5uPhFP61eBePn29vZwuVwkk0mcTifT09NlKQZEvurgYnEYMpkMqVSKUCjE7du3uXHjBsvLyzL3VlNTg8lkkoU8R/ldarVa6YUgNsloNMru7i7Nzc3PvNTFYpF4PE4sFiMcDhMKhWS9QCaTkdW45VK482VESHFvb0/Ojq+qqqKjowOr1Vp2PeGiRUs4V1osFhmx+bK1qpiLsbm5SW1tLT09Pbz55pu0tbVhMBhO8C6+wGg0Mjk5KZ9/4SyqUqmoqqpifHyc6elppqammJiYIJFIyFa4ra0tFhYWaGpqoqen51juSVhTT0xMMD8/L2tMIpGI7KWPRCKsrKzI9zSfz1NbW0tVVZX8d2LKrOjhHx0dlQ55J4EQm42NjdIeeWRkhLfeekt21oj3OJVKcf/+fW7evMnW1pbsuRdpgatXrzI+Ps74+LjsljqOiLSYwvn48WN2dnZk3cnLIKKGCwsL0nvk4Ijmb8uRiQGfz8fKyors6dZoNNL6cWBg4FhU2VEhClfW19flKFmbzYbD4ZDjmMuJbDbL7u7uNzalEDPc3W43n3/+OWtra0QiEfmS9vX10d3djcViOdLWPJVKJUP7g4ODbG1tEYlEmJ+fp1gs0tjY+MyLLeyhE4kEkUjkmbyvCLcbjcZjO7l9U3K5HPF4XPqni02ot7dXFoWVGwcLvp7HwRkL9+/fZ3d3V7ZXNTc3l9WQKK1WS3NzM2NjY7KlU0TV6uvrOX/+vGxtE738Ysy3KKZ0u914vV5GRkaO/Hp1Op2ssq+rq8PlcrGxsUGhUJChc2GQJNYmYY4mOh9UKhWFQkEKO6/XK43JDAYDDofjyO/jeYhODY1Gg91ul9dSLBblM1csFllfXweemmGJWSOidXp6epqLFy/KiM+XJy8eJaLOIRgMkkqlXnoUtxCde3t7rKysSBvm5ubml56vcGS7lhjysby8TDAYlL3RQ0NDDA8Pl+WCdliErbLL5SIUCsm8qTCvKadoh8g/x2KxQw/kEaEtt9vN3Nwcjx49kg5x6XRamkWdPXuW0dFROZDpKE+rYiLmxMSELNrc2dkhHo9jNBqf+98WoiAQCMh6AXhq6VlfXy9HmZYbor5hfX2dQqGARqNBr9czNDSExWI5le+OaK9aW1vj/v37BINB2SZptVrLyuehoqKChoYGKioqiMViMk2WSqWw2+1cvXqV/v5+Ghsb0el09PT0EA6HCQaDsmNqaWmJjo4OhoeHj/y+tFotDQ0NfOc738Fut9PU1MTHH39MNpuVpkjZbFauAX/NslZsvltbW1I4i4POSaJSqeS8hIODucQI7VAoxPb2NoFAQA4CMpvN9PT0cPnyZc6ePYvT6Tx2/xfRIixMrF4mKiBqn4Sd+vLyMqlUSrpems3mlzqIHokYKJVKXLt2jdu3b+NyuUin07S3t3PlyhXefPNNWXl+WhEhXBGmEYvaSRfdvCrS6TS3b9/mww8/ZGZmhidPnrC5uQl8ERJua2vjhz/8IePj4zgcjiM/1QkBcvXqVSorK1lcXGR9fV2GBA++ZGKgR0NDA2q1mtnZWdxuN6lUCnia3hAGN+WG8FNwu93cvn1bOjxarVYmJyfLLg11WMSkv9u3b/PkyRN0Oh1Wq1X6spdLVEBQU1Mj62FaWloIhULS9fLs2bPPRDJaW1tlXlg4ZM7Pz2M0Gnn33XePvKBYo9FgMpm4dOkSAwMDnDt3js7OTjKZDMFgUI729fv9+P1+9vb2iMViz/27xEEgm82yvLxMXV0dNpuNy5cvH9n1f1tEh9Dc3Bz/8z//w/3791lbWyObzVJbW0tnZyeXL1/m7bffxul0lmWH12ERB5uNjQ0WFhbkoKaamhrp1+N0Ol9qXz2yyMDS0pIc6AFPq257enro6ekBkNaqgi+PbjxoryhaM5LJ5DP9ovCFYjzOntpcLkc0GmVzc5NSqYTRaJQ+6qdBDIhe6VAoRCwWI5lMsr29LSMHsViM3/72tywsLBAIBAiFQnKzraqqwmw288Ybb8hq3ONIi4gTS319PW+88QYjIyOEQiH29vZIJpPPRDzUarWcgKlWq3nvvfe4ceOGPHGL50nYgpYTiURCFkG53W6KxSJms5m2tjZZ1FVuaajDUCwW2draYn5+nnQ6zcDAAMPDw/T19VFXV1d2YgCebrL19fXU1tZSKBQoFovS0/9g9K+iooL6+np6enoYHR2V7aAul4u1tTVpT3yUa4N4P6xWKwaDgfb2dkqlEsFgkFAoRDwe59GjR9y7d08W4ImxuAaDAYvFQiwWk7U2B6MJoVDoUF07x4lIfbhcLv73f/+Xzz77jN3dXbmvdHV1SU8OcVA7CcT3Ul1d/VJmVIVCgZ2dHe7evcuDBw+4d+8earWasbExJicn6enpeelU25F9QsLtToSkRLgkHA4/N28iBn2IQgihToW1ZzabJRAIsL6+LudTw9MPu7GxkeHhYWn4cZQIhRYOh9nc3KRYLGI0GqUqK6cXRiBy/OJBzOVy+P1+lpaWyOfz7O7u8uDBA1KplLw/EcpNpVLyOxBRAVEBLtyzjuueD9YOVFZWYjabaWhoIJfLPSMGKioqMBqNMn0gJrSJjb9QKMjisHITA8lkkv39fUKhEOl0WoZpOzs7pW1qOT5jf42D9QIi9dHe3k5HR4eM3pQrYvN/EbW1tTidTvr7+2WxmN/vZ2ZmBpPJJEcBHyXi/dBoNPKa6+rqsNvtMnq2v7+P3+9neXlZpt5aWloYGRlhY2MDn88n7XxFO+/LFrwdBeIAs7S0xOeff87u7q70GzAYDHKCoRhPfFLvzEGnTnEdh50hIOo9hMfK2toaMzMzLCws4PP5aGhoYHJykqGhIerr61/6PToyMfDlysZQKITL5aKqquq5L5foWRabuVCo0WhU5krW19fl2Enx36ioqJBTwkRl7FEiirv29vbY3NyUMxZEGKrcFuqDJ2qtVks6nSadTrO6usqNGzeIxWJsbm7ywQcfEI/Hn1tXIO5Jq9ViNpvp6OjgO9/5zonea2VlpSwEfBFVVVXPDM0RL9k36aw4LkTRo5i7rtPpaG5uZnh4uOy6CA6LsMv1+XxsbGwAyIlzNpvthK/u1SBE8tDQELOzs88M2RkYGMBgMJyIkBN5dni6poriRviifc/hcHDmzBnUajXpdJpAICD/fzF/otyIRqN4vV4ePXrE7OysbCWsrKykvb2dCxcuMDY2RktLy4m+MxqNBrPZjM1mkx4aYn6CaPN+HmLPC4VCJBIJ9vf3mZmZ4f79+3g8HhKJBJcvX+bSpUsMDw9TV1f38tf60n/D13Aw7F8qlbh+/TrXr1//2i9mdHSUxsZG7HY7KpUKr9crjUy+ctEHKmDVajUej0dOp3rrrbeO6pYAZJHQ6uoqsVhMhmaOevLVt0WtVmO32/nxj3/M2tqaTHH86U9/4s9//vNz/7w4DYjFQJiQCAvgN998syzv9es4mG6CL1IdJ10U9Tyy2SzJZFJWfpvNZiYmJvj+979flrn1FyFaWz/44AMePnxIOBxGr9fT2NhIQ0MDBoNBfi+n6Zl6Hlqtlv7+fq5cuUI0GmVhYYH//u//ZmpqipqaGtra2k60+NNqtcqIjEajIZvNsrS0hMfjwev1srW1RSwWI5FIyPSryWQqS3MuERVYWlp6Rgg4nU7+9V//lTfeeAO73X7i9TVVVVW0t7cTDoex2+3EYjEikQi7u7uEw+GvjVrkcjncbjcff/wxi4uLuFwuXC4Xu7u76PV6uru7+fd//3cGBwdfWYv+kYkB0W4jQuqCrwuPrK2t4fP5ZChNnGCBZzZatVpNT08PbW1tclRwQ0ODnGl/1Ihpax6PB61WS2trK/39/fT29pad8yB8UYU/NTWF0+kkEomQyWTkPAHguQ+SWAz0ej1Wq5Xz58/zxhtv0NnZWbZV+F/Hl6NUL9uPe5SIEcBbW1syZy1Mhk6bEICnp6BYLMb169dZWVlBrVYzODiIzWZDp9PJind4GgUpt7TNN0Gkp4aHh2WP//vvv8+HH35IqVSSRYkn1W0kRNjAwADj4+M8evSITCZDJpNhZWVFpnU1Gg0NDQ1cuHCBt956i7fffvtErvd5iO4ol8vFw4cPmZmZAZ4eEDs6OpiammJ8fPxYUsbfhkAgwLVr13C5XHzwwQdfG+3LZDK4XC48Hg/hcFhGbUXKcHJyku7u7lcaLTwSMaBSqZienpZjcsVUKfiiMDCRSBCNRmUaQIwMFZWxFotFnrgbGhpkAYZaraa9vZ3GxkYMBgM1NTXSjOZgy8lRUCwWCQaD+P1+AoGADEmJaynHxVqlUlFZWUlTUxMTExNUVlayvr7O5uambJv6OpxOJ+3t7XR3d3P16lUmJyexWCwnrra/KV9OfZSrGBD2zmKGAjw9WYh8czle84sQi3cwGHwmpyvGSW9vbxMOh7FYLNJz4DQjDIC6u7sZHR3lk08+YWlpSb5/drv9xGqLhIV0R0cHFy5cIBgMEgwGSafTJBIJtFotBoNBOhZevXqVsbGxsomgidqTlZUV7t27x9raGtFoFJVKhclkYmBggIsXL+JwOMpq3o1Ix/T39xMMBgmHwyQSCTY2Nr5WsOTzeXw+H7FYTNbd2Ww2hoeHGRkZYXp6+pWnno4sMvD2229jsVjo6emRVffwdEPN5XL4fD7W1tbweDxyQ7JYLLS0tNDX1ydrAPR6PePj47JYTRTDiRywCGEfR4FOoVAgFArh9/tluGZ4eJimpqayLR4EZM3AD37wA1paWlhaWuLmzZu4XC4ZISgWi/LB0mg0FItFhoaGOHfuHFNTU4yOjsqHr1xessOSz+fJ5XJydPPB+oFyQuQJE4kEqVRK2vk+b/LfaUIIAvGel0olmQKMRCKEQiEmJiZQq9WnXgzAUwdDERp2OBz4fD5cLhebm5t0dXXJQ81xo1arpQPsO++8w9bWFi6XC7/fTzgcxmQy0dzcTE9PD++88w6XLl2ioaGhbE7YQlR+9NFHXLt2Da/XS6FQoLKykubmZqampnjrrbfKbt5NRUUFFouFt99+W06XDAQCclbP13mkCBGg0+mora1lYGCAt956i4mJCcbGxl65p82RrYg2m41z584xMDDwTPX/wQl0kUiEWCz2TC5Xr9djMplkZ4Fol6murj7xvLw4UVZVVWG322lsbOTdd9+lt7e3rH0TRBGhaEHZ29tjampK2guvr6+zu7srrUdbWlpQq9UMDw/T2dlJW1vbqS70crlcuN1uotEoQ0NDnD9/ns7OzpO+rOdSW1uLyWTCbDYTiUSwWCzU1dWdajFwkEwmw71791hdXcVoNEob3b6+vrI5gb4sVVVVsrvo3/7t3/iv//ov1tfX+fjjj2WK86Sia1VVVdhsNs6fP4/JZGJhYYGFhQVWV1fl8LjOzk46OzuPrW34sIRCIdbW1nj48CFut5tYLIZarcZsNvOP//iP0ta63KJoarUai8XC9773PZxOJx999BE3b95kZmbma/0eqqqqGBsbo62tjba2Njo7O+XBs76+/kjMk470m9br9VRXV3+llVC0rIiKSoEoWDs4SUuc/MtB6anVarq7uykUCtINrqenB5PJdCoWaxFtMRqN0kzE5/MRCASIRCK0tLTIcadCzYo/e5oplUpYrVbGxsaYmJjgypUrZWk4pFKppA1uLpdDp9PR3t6O0Wg8Fc/X86ioqECv13Pu3DlUKhUejweLxUJXVxeNjY20trYyMjJCT08PZrP5pC/3lSAODBaLhfPnz9Pd3Y3X6+Xx48d4PB7q6+vlKPCTuDYxjGhwcJD6+no6Ozvx+/10dHRgt9ult0I5rLkH2dzcZHZ2FpfLRSaTke3F09PTXL58mY6OjrITAvD0M9fpdFgsFsbGxtBoNLS3t3P+/HnZwvlltFot3d3d2O12GhoaaGhowOFwHGkE/EifRrGx/62gUqmk4hd938KC+DQgvg8RdRFta/F4XLqric1f1BpotdpT7dwFT6NUvb29FItFzp49S2dnZ1luPCqVSgpMIZK7u7upr68/1WKgpqaGM2fOUCwWqa+vx2q10t/fT1NTEw6HQ852L9fBUd8GtVotIwSDg4Ny4FcgECAej8uU20lw0K+joqJCTikUIuCoh459W4LBIF6vl0AgQLFYpK6uDofDwfj4eNmLZiEIzGaznDHS29srx8p/GbVajdVqpa6uDr1ej16vP/Lx3uUTAzol2O127Hb7SV/GSyEKWk56dvxxMTg4SEdHB5WVlXR3d2M2m8tWpNbX19PX1ycNlex2Ow6Ho2wXuRdxMDJgtVrx+XzyHuvr66mrqyvL09yrQJzAxQnw5s2bsm+8HNwvVSoVdXV1pybyFw6H8fv97O/vo1KpqK+vp6OjQ9Y2nPTneRi0Wi1NTU00NTWd9KV8BUUMKPzNMzU1JX9f7puOVqvFbrdjs9kYHBws286Hb4JWq6W9vZ22trZnPAVO+30dBq1Wy/e+9z2sVismk4mmpqaybEE+DVRXV2MwGOS47J6eHqamppiamvqbiiqdFIoYUPib5zQuvH+Lm+Xf4j29CJFuGxoakiPODQbDqUktlhMtLS1MTk6ytbWFSqXi7NmzTE5OotfrT23krJxQxICCgoLCEXJwVobCt8fhcDA6OvrMMKLu7u6yTfmdNlSlw0xMUFBQUFBQUPibRYmtKCgoKCgovOYoYkBBQUFBQeE1RxEDCgoKCgoKrzmKGFBQUFBQUHjNUcSAgoKCgoLCa44iBhQUFBQUFF5zFDGgoKCgoKDwmqOIAQUFBQUFhdccRQwoKCgoKCi85ihiQEFBQUFB4TXn/wPBWeFn9wyk5QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display some images\n",
    "images, labels = next(iter(testloader))\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "figure = plt.figure()\n",
    "num_of_images = 10\n",
    "for index in range(1, num_of_images + 1):\n",
    "    plt.subplot(6, 10, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f1aa00c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T06:09:02.164856Z",
     "start_time": "2022-11-03T06:09:02.161191Z"
    }
   },
   "outputs": [],
   "source": [
    "# LeNet Model - Defined here upfront\n",
    "\n",
    "class CNN_LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_LeNet, self).__init__()\n",
    "        # Define the net structure\n",
    "        # This is the input layer first Convolution\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.fc1 = nn.Linear(400,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84, 10) \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.reshape(-1, 400)\n",
    "        #x = x.view(-1, 400)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        # Outputs are dequantized\n",
    "        x = F.softmax(x,dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e394f0b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T06:24:47.542143Z",
     "start_time": "2022-11-03T06:24:47.538231Z"
    }
   },
   "outputs": [],
   "source": [
    "# LeNet Model - I have created another version for quantized inference \n",
    "\n",
    "class CNN_LeNetQ(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_LeNetQ, self).__init__()\n",
    "        # Define the net structure\n",
    "        # This is the input layer first Convolution\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.fc1 = nn.Linear(400,120)\n",
    "        self.fc2 = nn.Linear(120,84)\n",
    "        self.fc3 = nn.Linear(84, 10) \n",
    "        self.quant = torch.quantization.QuantStub()\n",
    "        self.dequant = torch.quantization.DeQuantStub()\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.quant(x)\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = x.reshape(-1, 400)\n",
    "        #x = x.view(-1, 400)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        # Outputs are dequantized\n",
    "        x = self.dequant(x)\n",
    "        x = F.softmax(x,dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c00a200",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T06:10:26.097864Z",
     "start_time": "2022-11-03T06:10:26.082483Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the pre-trained model \n",
    "pretrained_model = \"./mnist_v0.pt\"\n",
    "net = CNN_LeNet()\n",
    "net.load_state_dict(torch.load(pretrained_model))\n",
    "state_dict = torch.load(pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "050f46df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T06:10:54.055288Z",
     "start_time": "2022-11-03T06:10:54.050500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Helper function for getting the model size\n",
    "def print_size_of_model(model):\n",
    "    \"\"\" Print the size of the model.\n",
    "    \n",
    "    Args:\n",
    "        model: model whose size needs to be determined\n",
    "\n",
    "    \"\"\"\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size of the model(KB):', os.path.getsize('temp.p')/1024)\n",
    "    os.remove('temp.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c11abcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T06:20:39.782281Z",
     "start_time": "2022-11-03T06:20:39.777854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the model(KB): 243.8193359375\n"
     ]
    }
   ],
   "source": [
    "print_size_of_model(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eeff1556",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T06:21:27.236375Z",
     "start_time": "2022-11-03T06:21:27.231973Z"
    }
   },
   "outputs": [],
   "source": [
    "# Main accuracy testing function\n",
    "def test(model, device, test_loader, train_loader, batch_size, quantize=False, fbgemm=False):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Testing with qauntization if quantize=True\n",
    "    if quantize:\n",
    "        if fbgemm:\n",
    "            model.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "        else:\n",
    "            model.qconfig = torch.quantization.default_qconfig\n",
    "        torch.quantization.prepare(model, inplace=True)\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data, target in train_loader:\n",
    "                model.forward(data)\n",
    "            torch.quantization.convert(model, inplace=True)\n",
    "            print(\"======= Quantization Done =====\")\n",
    "\n",
    "\n",
    "    print(model)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        st = time.time()\n",
    "        for data in test_loader:\n",
    "            X, y = data\n",
    "            st = time.time()\n",
    "            output = model.forward(X)\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == y[idx]:\n",
    "                #if True:\n",
    "                    correct += 1\n",
    "            total += batch_size\n",
    "        et = time.time()    \n",
    "    acc = round(correct/total, 4)\n",
    "    print(\"========================================= PERFORMANCE =============================================\")\n",
    "    print_size_of_model(model)\n",
    "    print(\"PyTorch optimized model test accuracy :{}% \".format(100*round(correct/total, 4)))\n",
    "    print('Elapsed time = {:0.4f} milliseconds'.format((et - st) * 1000))\n",
    "    print(\"====================================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37a03eb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T06:23:39.276342Z",
     "start_time": "2022-11-03T06:23:37.953707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "========================================= PERFORMANCE =============================================\n",
      "Size of the model(KB): 243.8193359375\n",
      "PyTorch optimized model test accuracy :99.03% \n",
      "Elapsed time = 0.6618 milliseconds\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "#Baseline performance - unquantized model\n",
    "device = 'cpu'\n",
    "test(model=net, device=device, test_loader=testloader, train_loader=trainloader, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "14390483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T06:41:08.531608Z",
     "start_time": "2022-11-03T06:40:58.962017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Quantization Done =====\n",
      "CNN_LeNetQ(\n",
      "  (conv1): QuantizedConv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), scale=0.1852394938468933, zero_point=87)\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): QuantizedConv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), scale=0.3763515055179596, zero_point=65)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): QuantizedLinear(in_features=400, out_features=120, scale=0.6366482377052307, zero_point=68, qscheme=torch.per_tensor_affine)\n",
      "  (fc2): QuantizedLinear(in_features=120, out_features=84, scale=0.5215939879417419, zero_point=43, qscheme=torch.per_tensor_affine)\n",
      "  (fc3): QuantizedLinear(in_features=84, out_features=10, scale=0.8862839341163635, zero_point=61, qscheme=torch.per_tensor_affine)\n",
      "  (quant): Quantize(scale=tensor([0.0272]), zero_point=tensor([17]), dtype=torch.quint8)\n",
      "  (dequant): DeQuantize()\n",
      ")\n",
      "========================================= PERFORMANCE =============================================\n",
      "Size of the model(KB): 67.4091796875\n",
      "PyTorch optimized model test accuracy :99.0% \n",
      "Elapsed time = 0.8750 milliseconds\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Quantization Performance\n",
    "# Load the model to be quantized with Pytorch Quantization\n",
    "pretrained_modelq = \"./mnist_v0.pt\"\n",
    "netq = CNN_LeNetQ()\n",
    "netq.load_state_dict(torch.load(pretrained_modelq))\n",
    "device = 'cpu'\n",
    "\n",
    "# This performs the quantized inference. This is PyTorch static quantization. We only did activations quantization\n",
    "# and performed the calibration required post training. The ACC drop is 0.03% only\n",
    "test(model=netq, device=device, test_loader=testloader, train_loader=trainloader, batch_size=bs, quantize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdacef46",
   "metadata": {},
   "source": [
    "## Section 2: From scratch post training quantization - with calibration  \n",
    "### As the FBGEMM backend is not available of FPGA and other embedded systems, we implement a simple quantization from scratch. We will take this to FPGA in the FPGA implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "522d9993",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T07:09:52.573491Z",
     "start_time": "2022-11-03T07:09:52.561585Z"
    }
   },
   "outputs": [],
   "source": [
    "# Routines for post training quantization - with calibration from scratch    \n",
    "    \n",
    "# Simple implementation for FPGA\n",
    "# Routines for Quantization    \n",
    "    \n",
    "from collections import namedtuple\n",
    "QTensor = namedtuple('QTensor', ['tensor', 'scale', 'zero_point'])\n",
    "nb = 8\n",
    "def calcScaleZeroPoint(min_val, max_val,num_bits=nb):\n",
    "  # Calc Scale and zero point of next \n",
    "  qmin = 0.\n",
    "  qmax = 2.**num_bits - 1. # potential math.pow() ?\n",
    "\n",
    "  scale = (max_val - min_val) / (qmax - qmin)\n",
    "\n",
    "  initial_zero_point = qmin - min_val / scale\n",
    "  \n",
    "  zero_point = 0\n",
    "  if initial_zero_point < qmin:\n",
    "      zero_point = qmin\n",
    "  elif initial_zero_point > qmax:\n",
    "      zero_point = qmax\n",
    "  else:\n",
    "      zero_point = initial_zero_point\n",
    "\n",
    "  zero_point = int(zero_point)\n",
    "\n",
    "  return scale, zero_point\n",
    "\n",
    "def quantize_tensor(x, ndims=10, all_dims=[0], num_bits=nb, minmax=False, min_val=0.3711, max_val=-0.3977):\n",
    "    if minmax:\n",
    "        if ndims == 1:\n",
    "            for i in range(all_dims[0]):\n",
    "                if min_val > x[i].item():\n",
    "                    min_val = x[i].item()\n",
    "                if max_val < x[i].item():\n",
    "                    max_val = x[i].item()\n",
    "        elif ndims == 2:\n",
    "            for i in range(all_dims[0]):\n",
    "                for j in range(all_dims[1]):\n",
    "                    if min_val > x[i][j].item():\n",
    "                        min_val = x[i][j].item()\n",
    "                    if max_val < x[i][j].item():\n",
    "                        max_val = x[i][j].item()\n",
    "        elif ndims == 3:\n",
    "            for i in range(all_dims[0]):\n",
    "                for j in range(all_dims[1]):\n",
    "                    for k in range(all_dims[2]):\n",
    "                        if min_val > x[i][j][k].item():\n",
    "                            min_val = x[i][j][k].item()\n",
    "                        if max_val < x[i][j][k].item():\n",
    "                            max_val = x[i][j][k].item() \n",
    "        elif ndims == 4:\n",
    "            for i in range(all_dims[0]):\n",
    "                for j in range(all_dims[1]):\n",
    "                    for k in range(all_dims[2]):\n",
    "                        for l in range(all_dims[3]):\n",
    "#                             print(\"i,j,k,l: \", i,j,k,l)\n",
    "#                             print(\"i,j,k,l: \", all_dims[0],all_dims[1],all_dims[2],all_dims[3])\n",
    "#                             print(x.shape)\n",
    "                            if min_val > x[i][j][k][l].item():\n",
    "                                min_val = x[i][j][k][l].item()\n",
    "                            if max_val < x[i][j][k][l].item():\n",
    "                                max_val = x[i][j][k][l].item() \n",
    "        else:\n",
    "            print(\"unexpected dims: \", ndims, all_dims)\n",
    "    #print(\"min, max :\", min_val,  max_val )     \n",
    "    qmin = 0.\n",
    "    qmax = 2.**num_bits - 1.\n",
    "\n",
    "    scale, zero_point = calcScaleZeroPoint(min_val, max_val, num_bits)\n",
    "    q_x = zero_point + x / scale\n",
    "    q_x.clamp_(qmin, qmax).round_()\n",
    "    q_x = q_x.round().byte()\n",
    "    \n",
    "    return QTensor(tensor=q_x, scale=scale, zero_point=zero_point)\n",
    "\n",
    "def dequantize_tensor(q_x):\n",
    "    return q_x.scale * (q_x.tensor.float() - q_x.zero_point)\n",
    "  # quantizeLayer(x.tensor, ndims, all_dims, model.conv1, stats['conv2'], x.scale, x.zero_point \n",
    "def quantizeLayer(x,  layer, stat, scale_x, zp_x, num_bits=nb):\n",
    "  # for both conv and linear layers\n",
    "  W = layer.weight.data\n",
    "  B = layer.bias.data\n",
    "\n",
    "  # scale_x = x.scale\n",
    "  # zp_x = x.zero_point\n",
    "\n",
    "\n",
    "  # Find the dimensions for the input\n",
    "  ndims = len(W.shape)\n",
    "  all_dims = list(W.shape)\n",
    "  #print(\"ndims, all_dims: \",ndims, all_dims)\n",
    "  w = quantize_tensor(layer.weight.data, ndims, all_dims, num_bits, minmax=True) \n",
    "  ndims = len(B.shape)\n",
    "  all_dims = list(B.shape)\n",
    "  #print(\"ndims, all_dims: \",ndims, all_dims)\n",
    "  b = quantize_tensor(layer.bias.data, ndims, all_dims, num_bits, minmax=True)\n",
    "\n",
    "  layer.weight.data = w.tensor.float()\n",
    "  layer.bias.data = b.tensor.float()\n",
    "\n",
    "  ####################################################################\n",
    "  # This is Quantisation !!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "  scale_w = w.scale\n",
    "  zp_w = w.zero_point\n",
    "  \n",
    "  scale_b = b.scale\n",
    "  zp_b = b.zero_point\n",
    "  \n",
    "\n",
    "  scale_next, zero_point_next = calcScaleZeroPoint(min_val=stat['min'], max_val=stat['max'])\n",
    "\n",
    "  # Perparing input by shifting\n",
    "  X = x.float() - zp_x\n",
    "  layer.weight.data = (scale_x * scale_w/scale_next)*(layer.weight.data - zp_w)\n",
    "  layer.bias.data = (scale_b/scale_next)*(layer.bias.data + zp_b)\n",
    "\n",
    "  # All int\n",
    "\n",
    "  x = layer(X) + zero_point_next\n",
    "  x = F.relu(x)  \n",
    "    \n",
    "  # Reset\n",
    "  layer.weight.data = W\n",
    "  layer.bias.data = B\n",
    "  \n",
    "  return x, scale_next, zero_point_next\n",
    "\n",
    "\n",
    "def quantForward(model, x, stats):\n",
    "    \n",
    "  # Quantise before inputting into incoming layers\n",
    "  x = quantize_tensor(x, min_val=stats['conv1']['min'], max_val=stats['conv1']['max'])\n",
    "    \n",
    "  x, scale_next, zero_point_next = quantizeLayer(x.tensor, model.conv1, stats['conv2'], x.scale, x.zero_point)\n",
    "  x = F.max_pool2d(x, 2, 2)\n",
    "  x, scale_next, zero_point_next = quantizeLayer(x,  model.conv2, stats['fc1'], scale_next, zero_point_next)\n",
    "  x = F.max_pool2d(x, 2, 2)\n",
    "  x = x.reshape(-1, 400)  \n",
    "  x, scale_next, zero_point_next = quantizeLayer(x, model.fc1, stats['fc2'], scale_next, zero_point_next)\n",
    "  x, scale_next, zero_point_next = quantizeLayer(x, model.fc2, stats['fc3'], scale_next, zero_point_next)\n",
    "    \n",
    "  \n",
    "  # Back to dequant for final layer\n",
    "  x = dequantize_tensor(QTensor(tensor=x, scale=scale_next, zero_point=zero_point_next))\n",
    "   \n",
    "  x = model.fc3(x)\n",
    "  x = F.softmax(x,dim=1)\n",
    "  return x\n",
    "\n",
    "def test_quant_scratch(model, device, test_loader, train_loader, batch_size, quantize=False, fbgemm=False, stats=None):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(model)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        st = time.time()\n",
    "        for data in test_loader:\n",
    "            X, y = data\n",
    "            #st = time.time()\n",
    "            # Testing with qauntization if quantize=True\n",
    "            if quantize:\n",
    "                output = quantForward(model, X, stats)\n",
    "            else:    \n",
    "                output = model.forward(X)\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == y[idx]:\n",
    "                #if True:\n",
    "                    correct += 1\n",
    "            total += batch_size\n",
    "        et = time.time()    \n",
    "    acc = round(correct/total, 4)\n",
    "    print(\"========================================= PERFORMANCE =============================================\")\n",
    "    print_size_of_model(model)\n",
    "    print(\"PyTorch optimized model test accuracy :{}% \".format(100*round(correct/total, 4)))\n",
    "    print('Elapsed time = {:0.4f} milliseconds'.format((et - st) * 1000))\n",
    "    print(\"====================================================================================================\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4aa2b330",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T07:12:13.346051Z",
     "start_time": "2022-11-03T07:12:05.122820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv1': {'max': tensor(47.7186), 'min': tensor(-7.2398)}, 'conv2': {'max': tensor(99.3117), 'min': tensor(0.)}, 'fc1': {'max': tensor(207.4083), 'min': tensor(0.)}, 'fc2': {'max': tensor(280.4087), 'min': tensor(0.)}, 'fc3': {'max': tensor(336.0337), 'min': tensor(0.)}}\n"
     ]
    }
   ],
   "source": [
    "# Quantized model performance\n",
    "# Copy from the original model for Q\n",
    "import copy\n",
    "netqq = copy.deepcopy(net)\n",
    "\n",
    "# one time stats gathering - we will keep this stored for MNIST FPGA implementation\n",
    "# This is doing the required calibration for finding the min, max of the activations\n",
    "stats = gatherStats(netqq, trainloader)\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0ad5dd8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T07:15:51.710891Z",
     "start_time": "2022-11-03T07:12:46.993649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_LeNet(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n",
      "========================================= PERFORMANCE =============================================\n",
      "Size of the model(KB): 243.8193359375\n",
      "PyTorch optimized model test accuracy :99.05000000000001% \n",
      "Elapsed time = 184712.4412 milliseconds\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Quantized Inference\n",
    "test_quant_scratch(model=netqq, device=device, test_loader=testloader, train_loader=trainloader, batch_size=bs, quantize=True, stats=stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b345e8",
   "metadata": {},
   "source": [
    "###  We get better performance than the PyTorch inference, with both activation and weight quantization. We will take this to FPGA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeb6da7f",
   "metadata": {},
   "source": [
    "## Section 3: DietCNN Inference - Multiplication Free \n",
    "### The main efficacy of this is in the FPGA implementation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fef7cd36",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T07:20:09.283156Z",
     "start_time": "2022-11-03T07:20:09.172551Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchvision import transforms, datasets\n",
    "import os\n",
    "# For training\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision\n",
    "from torchvision import utils\n",
    "import sys\n",
    "sys.path.insert(1, '../core')\n",
    "from typing import Type, Any, Callable, Union, List, Optional\n",
    "from torch import Tensor\n",
    "#from mnist_modeldef import *\n",
    "from mnist_modeldef_full import *\n",
    "from  patchlib import *\n",
    "import faiss \n",
    "       \n",
    "import os\n",
    "import numpy\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a1369ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T07:21:24.688587Z",
     "start_time": "2022-11-03T07:21:24.674582Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test method for the DietCNN MNIST Network. Stand alone Python file is also provided \n",
    "# with instrumentation functions for MNIST DietCNN inference\n",
    "HOWDY = 20000000 \n",
    "\n",
    "# Test accuracy of symbolic inference\n",
    "def test_fullsym_acc(model, atk,  data_iter, batch_size, clamp, top_5, std):\n",
    "    correct = 0 \n",
    "    total = 0 \n",
    "    counter = 0\n",
    "    model.eval()\n",
    "    for data in data_iter:\n",
    "        X, y = data\n",
    "        if counter > HOWDY:\n",
    "            break\n",
    "        if(clamp):\n",
    "            X = softclamp01(X)\n",
    "        if atk:\n",
    "            X_atk = atk(X, y)\n",
    "            X_sym = X_atk.data.cpu().numpy().copy()\n",
    "        else:\n",
    "            X_atk = X\n",
    "            X_sym = X  \n",
    "\n",
    "        output = model.forward(X)\n",
    "        if not top_5:\n",
    "            for idx, i in enumerate(output):\n",
    "                if torch.argmax(i) == y[idx]:\n",
    "                #if True:\n",
    "                    correct += 1\n",
    "        else:\n",
    "           top5op = output.detach().numpy()\n",
    "           for idx, i in enumerate(top5op):\n",
    "               ind = np.argpartition(i, -5)[-5:]\n",
    "               for j in ind:\n",
    "                   flag = 0\n",
    "                   if j == y[idx]:\n",
    "                       correct += 1\n",
    "            #else:\n",
    "            #    # Whenever there is an error, print the image\n",
    "            #    print(\"Test Image #: {}\".format(total+1))\n",
    "            #    print(\"Mispredicted label: {}\".format(torch.argmax(i)))\n",
    "        counter +=batch_size \n",
    "        total += batch_size\n",
    "        if std == 0: \n",
    "            if not top_5:\n",
    "                if(counter > 0 and counter % batch_size == 0):\n",
    "                    print(\"PyTorch optimized model test accuracy :{}% \".format(100*round(correct/total, 4)))\n",
    "            else:\n",
    "                if(counter > 0 and counter % batch_size == 0):\n",
    "                    print(\"PyTorch  model test accuracy Top-5 :{}% \".format(100*round(correct/total, 4)))\n",
    "        elif std == 1: \n",
    "            if not top_5:\n",
    "                if(counter > 0 and counter % batch_size == 0):\n",
    "                    print(\"Full standard model test accuracy :{}% \".format(100*round(correct/total, 4)))\n",
    "            else:\n",
    "                if(counter > 0 and counter % batch_size == 0):\n",
    "                    print(\"Full standard  model test accuracy Top-5 :{}% \".format(100*round(correct/total, 4)))\n",
    "        else:\n",
    "            if not top_5:\n",
    "                if(counter > 0 and counter % batch_size == 0):\n",
    "                    print(\"Full symbolic model test accuracy DietCNN :{}% \".format(100*round(correct/total, 4)))\n",
    "            else:\n",
    "                if(counter > 0 and counter % batch_size == 0):\n",
    "                    print(\"Full symbolic model test accuracy Top-5 DietCNN :{}% \".format(100*round(correct/total, 4)))\n",
    "        #break \n",
    "    return round(correct/total, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d82ad7bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-03T07:41:31.058834Z",
     "start_time": "2022-11-03T07:22:36.384498Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full standard model test accuracy :100.0% \n",
      "Full standard model test accuracy :96.88% \n",
      "Full standard model test accuracy :97.92% \n",
      "Full standard model test accuracy :98.44000000000001% \n",
      "Full standard model test accuracy :98.75% \n",
      "Full standard model test accuracy :98.96000000000001% \n",
      "Full standard model test accuracy :99.11% \n",
      "Full standard model test accuracy :99.22% \n",
      "Full standard model test accuracy :99.31% \n",
      "Full standard model test accuracy :99.38% \n",
      "Full standard model test accuracy :99.42999999999999% \n",
      "Full standard model test accuracy :99.48% \n",
      "Full standard model test accuracy :99.52% \n",
      "Full standard model test accuracy :99.55000000000001% \n",
      "Full standard model test accuracy :99.58% \n",
      "Full standard model test accuracy :99.22% \n",
      "Full standard model test accuracy :98.9% \n",
      "Full standard model test accuracy :98.96000000000001% \n",
      "Full standard model test accuracy :98.68% \n",
      "Full standard model test accuracy :98.75% \n",
      "Full standard model test accuracy :98.50999999999999% \n",
      "Full standard model test accuracy :98.58% \n",
      "Full standard model test accuracy :98.64% \n",
      "Full standard model test accuracy :98.7% \n",
      "Full standard model test accuracy :98.75% \n",
      "Full standard model test accuracy :98.8% \n",
      "Full standard model test accuracy :98.83999999999999% \n",
      "Full standard model test accuracy :98.66% \n",
      "Full standard model test accuracy :98.49% \n",
      "Full standard model test accuracy :98.54% \n",
      "Full standard model test accuracy :98.59% \n",
      "Full standard model test accuracy :98.63% \n",
      "Full standard model test accuracy :98.67% \n",
      "Full standard model test accuracy :98.71% \n",
      "Full standard model test accuracy :98.75% \n",
      "Full standard model test accuracy :98.78% \n",
      "Full standard model test accuracy :98.65% \n",
      "Full standard model test accuracy :98.68% \n",
      "Full standard model test accuracy :98.72% \n",
      "Full standard model test accuracy :98.59% \n",
      "Full standard model test accuracy :98.63% \n",
      "Full standard model test accuracy :98.50999999999999% \n",
      "Full standard model test accuracy :98.55000000000001% \n",
      "Full standard model test accuracy :98.44000000000001% \n",
      "Full standard model test accuracy :98.47% \n",
      "Full standard model test accuracy :98.37% \n",
      "Full standard model test accuracy :98.27% \n",
      "Full standard model test accuracy :98.18% \n",
      "Full standard model test accuracy :98.21% \n",
      "Full standard model test accuracy :98.25% \n",
      "Full standard model test accuracy :98.28% \n",
      "Full standard model test accuracy :98.32% \n",
      "Full standard model test accuracy :98.35000000000001% \n",
      "Full standard model test accuracy :98.38% \n",
      "Full standard model test accuracy :98.41% \n",
      "Full standard model test accuracy :98.33% \n",
      "Full standard model test accuracy :98.36% \n",
      "Full standard model test accuracy :98.38% \n",
      "Full standard model test accuracy :98.31% \n",
      "Full standard model test accuracy :98.11999999999999% \n",
      "Full standard model test accuracy :98.05% \n",
      "Full standard model test accuracy :98.08% \n",
      "Full standard model test accuracy :98.11999999999999% \n",
      "Full standard model test accuracy :98.05% \n",
      "Full standard model test accuracy :98.08% \n",
      "Full standard model test accuracy :98.11% \n",
      "Full standard model test accuracy :98.13% \n",
      "Full standard model test accuracy :98.07000000000001% \n",
      "Full standard model test accuracy :98.1% \n",
      "Full standard model test accuracy :98.11999999999999% \n",
      "Full standard model test accuracy :98.15% \n",
      "Full standard model test accuracy :98.18% \n",
      "Full standard model test accuracy :98.2% \n",
      "Full standard model test accuracy :98.22999999999999% \n",
      "Full standard model test accuracy :98.25% \n",
      "Full standard model test accuracy :98.27% \n",
      "Full standard model test accuracy :98.21% \n",
      "Full standard model test accuracy :98.0% \n",
      "Full standard model test accuracy :98.02% \n",
      "Full standard model test accuracy :97.97% \n",
      "Full standard model test accuracy :97.99% \n",
      "Full standard model test accuracy :98.02% \n",
      "Full standard model test accuracy :97.89% \n",
      "Full standard model test accuracy :97.84% \n",
      "Full standard model test accuracy :97.87% \n",
      "Full standard model test accuracy :97.89% \n",
      "Full standard model test accuracy :97.92% \n",
      "Full standard model test accuracy :97.94% \n",
      "Full standard model test accuracy :97.89% \n",
      "Full standard model test accuracy :97.85000000000001% \n",
      "Full standard model test accuracy :97.87% \n",
      "Full standard model test accuracy :97.83% \n",
      "Full standard model test accuracy :97.85000000000001% \n",
      "Full standard model test accuracy :97.81% \n",
      "Full standard model test accuracy :97.83% \n",
      "Full standard model test accuracy :97.72% \n",
      "Full standard model test accuracy :97.74000000000001% \n",
      "Full standard model test accuracy :97.7% \n",
      "Full standard model test accuracy :97.72999999999999% \n",
      "Full standard model test accuracy :97.75% \n",
      "Full standard model test accuracy :97.77% \n",
      "Full standard model test accuracy :97.78999999999999% \n",
      "Full standard model test accuracy :97.82% \n",
      "Full standard model test accuracy :97.84% \n",
      "Full standard model test accuracy :97.8% \n",
      "Full standard model test accuracy :97.76% \n",
      "Full standard model test accuracy :97.72% \n",
      "Full standard model test accuracy :97.74000000000001% \n",
      "Full standard model test accuracy :97.76% \n",
      "Full standard model test accuracy :97.78% \n",
      "Full standard model test accuracy :97.8% \n",
      "Full standard model test accuracy :97.82% \n",
      "Full standard model test accuracy :97.84% \n",
      "Full standard model test accuracy :97.86% \n",
      "Full standard model test accuracy :97.88% \n",
      "Full standard model test accuracy :97.89999999999999% \n",
      "Full standard model test accuracy :97.92% \n",
      "Full standard model test accuracy :97.92999999999999% \n",
      "Full standard model test accuracy :97.89999999999999% \n",
      "Full standard model test accuracy :97.92% \n",
      "Full standard model test accuracy :97.92999999999999% \n",
      "Full standard model test accuracy :97.95% \n",
      "Full standard model test accuracy :97.97% \n",
      "Full standard model test accuracy :97.98% \n",
      "Full standard model test accuracy :98.0% \n",
      "Full standard model test accuracy :98.02% \n",
      "Full standard model test accuracy :97.98% \n",
      "Full standard model test accuracy :97.95% \n",
      "Full standard model test accuracy :97.92% \n",
      "Full standard model test accuracy :97.92999999999999% \n",
      "Full standard model test accuracy :97.95% \n",
      "Full standard model test accuracy :97.92% \n",
      "Full standard model test accuracy :97.89% \n",
      "Full standard model test accuracy :97.81% \n",
      "Full standard model test accuracy :97.82% \n",
      "Full standard model test accuracy :97.84% \n",
      "Full standard model test accuracy :97.81% \n",
      "Full standard model test accuracy :97.83% \n",
      "Full standard model test accuracy :97.84% \n",
      "Full standard model test accuracy :97.81% \n",
      "Full standard model test accuracy :97.83% \n",
      "Full standard model test accuracy :97.8% \n",
      "Full standard model test accuracy :97.81% \n",
      "Full standard model test accuracy :97.78999999999999% \n",
      "Full standard model test accuracy :97.76% \n",
      "Full standard model test accuracy :97.77% \n",
      "Full standard model test accuracy :97.78999999999999% \n",
      "Full standard model test accuracy :97.8% \n",
      "Full standard model test accuracy :97.78% \n",
      "Full standard model test accuracy :97.75% \n",
      "Full standard model test accuracy :97.72% \n",
      "Full standard model test accuracy :97.74000000000001% \n",
      "Full standard model test accuracy :97.71% \n",
      "Full standard model test accuracy :97.69% \n",
      "Full standard model test accuracy :97.7% \n",
      "Full standard model test accuracy :97.68% \n",
      "Full standard model test accuracy :97.69% \n",
      "Full standard model test accuracy :97.71% \n",
      "Full standard model test accuracy :97.72% \n",
      "Full standard model test accuracy :97.72999999999999% \n",
      "Full standard model test accuracy :97.75% \n",
      "Full standard model test accuracy :97.72% \n",
      "Full standard model test accuracy :97.7% \n",
      "Full standard model test accuracy :97.71% \n",
      "Full standard model test accuracy :97.72999999999999% \n",
      "Full standard model test accuracy :97.7% \n",
      "Full standard model test accuracy :97.72% \n",
      "Full standard model test accuracy :97.72999999999999% \n",
      "Full standard model test accuracy :97.74000000000001% \n",
      "Full standard model test accuracy :97.76% \n",
      "Full standard model test accuracy :97.77% \n",
      "Full standard model test accuracy :97.75% \n",
      "Full standard model test accuracy :97.76% \n",
      "Full standard model test accuracy :97.74000000000001% \n",
      "Full standard model test accuracy :97.75% \n",
      "Full standard model test accuracy :97.76% \n",
      "Full standard model test accuracy :97.74000000000001% \n",
      "Full standard model test accuracy :97.75% \n",
      "Full standard model test accuracy :97.77% \n",
      "Full standard model test accuracy :97.78% \n",
      "Full standard model test accuracy :97.78999999999999% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full standard model test accuracy :97.77% \n",
      "Full standard model test accuracy :97.75% \n",
      "Full standard model test accuracy :97.72% \n",
      "Full standard model test accuracy :97.7% \n",
      "Full standard model test accuracy :97.72% \n",
      "Full standard model test accuracy :97.72999999999999% \n",
      "Full standard model test accuracy :97.71% \n",
      "Full standard model test accuracy :97.72% \n",
      "Full standard model test accuracy :97.7% \n",
      "Full standard model test accuracy :97.71% \n",
      "Full standard model test accuracy :97.69% \n",
      "Full standard model test accuracy :97.7% \n",
      "Full standard model test accuracy :97.71% \n",
      "Full standard model test accuracy :97.72% \n",
      "Full standard model test accuracy :97.74000000000001% \n",
      "Full standard model test accuracy :97.75% \n",
      "Full standard model test accuracy :97.76% \n",
      "Full standard model test accuracy :97.77% \n",
      "Full standard model test accuracy :97.78% \n",
      "Full standard model test accuracy :97.78999999999999% \n",
      "Full standard model test accuracy :97.77% \n",
      "Full standard model test accuracy :97.78% \n",
      "Full standard model test accuracy :97.78999999999999% \n",
      "Full standard model test accuracy :97.8% \n",
      "Full standard model test accuracy :97.82% \n",
      "Full standard model test accuracy :97.83% \n",
      "Full standard model test accuracy :97.84% \n",
      "Full standard model test accuracy :97.82% \n",
      "Full standard model test accuracy :97.83% \n",
      "Full standard model test accuracy :97.84% \n",
      "Full standard model test accuracy :97.85000000000001% \n",
      "Full standard model test accuracy :97.86% \n",
      "Full standard model test accuracy :97.84% \n",
      "Full standard model test accuracy :97.85000000000001% \n",
      "Full standard model test accuracy :97.86% \n",
      "Full standard model test accuracy :97.87% \n",
      "Full standard model test accuracy :97.85000000000001% \n",
      "Full standard model test accuracy :97.83% \n",
      "Full standard model test accuracy :97.84% \n",
      "Full standard model test accuracy :97.82% \n",
      "Full standard model test accuracy :97.83% \n",
      "Full standard model test accuracy :97.81% \n",
      "Full standard model test accuracy :97.82% \n",
      "Full standard model test accuracy :97.83% \n",
      "Full standard model test accuracy :97.84% \n",
      "Full standard model test accuracy :97.85000000000001% \n",
      "Full standard model test accuracy :97.86% \n",
      "Full standard model test accuracy :97.87% \n",
      "Full standard model test accuracy :97.88% \n",
      "Full standard model test accuracy :97.86% \n",
      "Full standard model test accuracy :97.87% \n",
      "Full standard model test accuracy :97.83% \n",
      "Full standard model test accuracy :97.84% \n",
      "Full standard model test accuracy :97.78999999999999% \n",
      "Full standard model test accuracy :97.75% \n",
      "Full standard model test accuracy :97.72999999999999% \n",
      "Full standard model test accuracy :97.74000000000001% \n",
      "Full standard model test accuracy :97.72% \n",
      "Full standard model test accuracy :97.72999999999999% \n",
      "Full standard model test accuracy :97.74000000000001% \n",
      "Full standard model test accuracy :97.75% \n",
      "Full standard model test accuracy :97.76% \n",
      "Full standard model test accuracy :97.77% \n",
      "Full standard model test accuracy :97.78% \n",
      "Full standard model test accuracy :97.78999999999999% \n",
      "Full standard model test accuracy :97.75% \n",
      "Full standard model test accuracy :97.76% \n",
      "Full standard model test accuracy :97.77% \n",
      "Full standard model test accuracy :97.75% \n",
      "Full standard model test accuracy :97.72999999999999% \n",
      "Full standard model test accuracy :97.74000000000001% \n",
      "Full standard model test accuracy :97.75% \n",
      "Full standard model test accuracy :97.76% \n",
      "Full standard model test accuracy :97.77% \n",
      "Full standard model test accuracy :97.78% \n",
      "Full standard model test accuracy :97.78999999999999% \n",
      "Full standard model test accuracy :97.8% \n",
      "Full standard model test accuracy :97.8% \n",
      "Full standard model test accuracy :97.81% \n",
      "Full standard model test accuracy :97.8% \n",
      "Full standard model test accuracy :97.78% \n",
      "Full standard model test accuracy :97.78999999999999% \n",
      "Full standard model test accuracy :97.8% \n",
      "Full standard model test accuracy :97.81% \n",
      "Full standard model test accuracy :97.78999999999999% \n",
      "Full standard model test accuracy :97.75% \n",
      "Full standard model test accuracy :97.74000000000001% \n",
      "Full standard model test accuracy :97.75% \n",
      "Full standard model test accuracy :97.75% \n",
      "Full standard model test accuracy :97.76% \n",
      "Full standard model test accuracy :97.77% \n",
      "Full standard model test accuracy :97.78% \n",
      "Full standard model test accuracy :97.78999999999999% \n",
      "Full standard model test accuracy :97.8% \n",
      "Full standard model test accuracy :97.8% \n",
      "Full standard model test accuracy :97.81% \n",
      "Full standard model test accuracy :97.8% \n",
      "Full standard model test accuracy :97.8% \n",
      "Full standard model test accuracy :97.81% \n",
      "Full standard model test accuracy :97.82% \n",
      "Full standard model test accuracy :97.78% \n",
      "Full standard model test accuracy :97.78999999999999% \n",
      "Full standard model test accuracy :97.8% \n",
      "Full standard model test accuracy :97.78999999999999% \n",
      "Full standard model test accuracy :97.78999999999999% \n",
      "Full standard model test accuracy :97.8% \n",
      "Full standard model test accuracy :97.78999999999999% \n",
      "Full standard model test accuracy :97.78999999999999% \n",
      "Full standard model test accuracy :97.8% \n",
      "Full standard model test accuracy :97.81% \n",
      "Full standard model test accuracy :97.82% \n",
      "Full standard model test accuracy :97.82% \n",
      "Full standard model test accuracy :97.81% \n",
      "Full standard model test accuracy :97.82% \n",
      "Full standard model test accuracy :97.83% \n",
      "Full standard model test accuracy :97.83% \n",
      "Full standard model test accuracy :97.82% \n",
      "Full standard model test accuracy :97.83% \n",
      "Full standard model test accuracy :97.83% \n",
      "Full standard model test accuracy :97.82% \n",
      "Full standard model test accuracy :97.81% \n",
      "Full standard model test accuracy :97.81% \n",
      "Full standard model test accuracy :97.8% \n",
      "Full standard model test accuracy :97.81% \n",
      "Full standard model test accuracy :97.78999999999999% \n",
      "Full standard model test accuracy :97.78% \n",
      "Full standard model test accuracy :97.78999999999999% \n",
      "Full standard model test accuracy :97.8% \n",
      "Full standard model test accuracy :97.78% \n",
      "Full standard model test accuracy :97.78999999999999% \n",
      "Full standard model test accuracy :97.8% \n",
      "Full standard model test accuracy :97.8% \n",
      "Full standard model test accuracy :97.81% \n",
      "Full standard model test accuracy :97.82% \n",
      "Full standard model test accuracy :97.82% \n",
      "Full standard model test accuracy :97.83% \n",
      "Full standard model test accuracy :97.84% \n",
      "Full standard model test accuracy :97.84% \n",
      "Full standard model test accuracy :97.85000000000001% \n",
      "Full standard model test accuracy :97.86% \n",
      "Full standard model test accuracy :97.86% \n",
      "Full standard model test accuracy :97.87% \n",
      "Full standard model test accuracy :97.88% \n",
      "Full standard model test accuracy :97.88% \n",
      "Full standard model test accuracy :97.87% \n",
      "Full standard model test accuracy :97.88% \n",
      "Full standard model test accuracy :97.88% \n",
      "Full standard model test accuracy :97.89% \n",
      "Full standard model test accuracy :97.86% \n",
      "Full standard model test accuracy :97.87% \n",
      "Full standard model test accuracy :97.87% \n",
      "Full standard model test accuracy :97.88% \n",
      "Full standard model test accuracy :97.89% \n",
      "Full standard model test accuracy :97.89% \n",
      "Full standard model test accuracy :97.89999999999999% \n",
      "Full standard model test accuracy :97.89999999999999% \n",
      "Full standard model test accuracy :97.91% \n",
      "Full standard model test accuracy :97.92% \n",
      "Full standard model test accuracy :97.92% \n",
      "Full standard model test accuracy :97.92999999999999% \n",
      "Full standard model test accuracy :97.92999999999999% \n",
      "Full standard model test accuracy :97.94% \n",
      "Full standard model test accuracy :97.95% \n",
      "Full standard model test accuracy :97.95% \n",
      "Full standard model test accuracy :97.96000000000001% \n",
      "Full standard model test accuracy :97.96000000000001% \n",
      "Full standard model test accuracy :97.97% \n",
      "Full standard model test accuracy :97.98% \n",
      "Full standard model test accuracy :97.98% \n",
      "Full standard model test accuracy :97.99% \n",
      "Full standard model test accuracy :97.99% \n",
      "Full standard model test accuracy :97.98% \n",
      "Full standard model test accuracy :97.99% \n",
      "Full standard model test accuracy :97.99% \n",
      "Full standard model test accuracy :98.0% \n",
      "Full standard model test accuracy :98.0% \n",
      "Full standard model test accuracy :98.00999999999999% \n",
      "Full standard model test accuracy :98.02% \n",
      "Full standard model test accuracy :98.02% \n",
      "Full standard model test accuracy :98.03% \n",
      "Full standard model test accuracy :98.03% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full standard model test accuracy :98.04% \n",
      "Full standard model test accuracy :98.04% \n",
      "Full standard model test accuracy :98.05% \n",
      "Full standard model test accuracy :98.05% \n",
      "Full standard model test accuracy :98.06% \n",
      "Full standard model test accuracy :98.05% \n",
      "Full standard model test accuracy :98.05% \n",
      "Full standard model test accuracy :98.06% \n",
      "Full standard model test accuracy :98.06% \n",
      "Full standard model test accuracy :98.05% \n",
      "Full standard model test accuracy :98.04% \n",
      "Full standard model test accuracy :98.04% \n",
      "Full standard model test accuracy :98.05% \n",
      "Full standard model test accuracy :98.06% \n",
      "Full standard model test accuracy :98.04% \n",
      "Full standard model test accuracy :98.05% \n",
      "Full standard model test accuracy :98.05% \n",
      "Full standard model test accuracy :98.06% \n",
      "Full standard model test accuracy :98.06% \n",
      "Full standard model test accuracy :98.07000000000001% \n",
      "Full standard model test accuracy :98.07000000000001% \n",
      "Full standard model test accuracy :98.08% \n",
      "Full standard model test accuracy :98.08% \n",
      "Full standard model test accuracy :98.09% \n",
      "Full standard model test accuracy :98.09% \n",
      "Full standard model test accuracy :98.1% \n",
      "Full standard model test accuracy :98.1% \n",
      "Full standard model test accuracy :98.11% \n",
      "Full standard model test accuracy :98.11% \n",
      "Full standard model test accuracy :98.11999999999999% \n",
      "Full standard model test accuracy :98.11999999999999% \n",
      "Full standard model test accuracy :98.13% \n",
      "Full standard model test accuracy :98.13% \n",
      "Full standard model test accuracy :98.14% \n",
      "Full standard model test accuracy :98.14% \n",
      "Full standard model test accuracy :98.15% \n",
      "Full standard model test accuracy :98.15% \n",
      "Full standard model test accuracy :98.16% \n",
      "Full standard model test accuracy :98.16% \n",
      "Full standard model test accuracy :98.17% \n",
      "Full standard model test accuracy :98.17% \n",
      "Full standard model test accuracy :98.17% \n",
      "Full standard model test accuracy :98.18% \n",
      "Full standard model test accuracy :98.18% \n",
      "Full standard model test accuracy :98.17% \n",
      "Full standard model test accuracy :98.18% \n",
      "Full standard model test accuracy :98.18% \n",
      "Full standard model test accuracy :98.19% \n",
      "Full standard model test accuracy :98.16% \n",
      "Full standard model test accuracy :98.13% \n",
      "Full standard model test accuracy :98.11999999999999% \n",
      "Full standard model test accuracy :98.13% \n",
      "Full standard model test accuracy :98.13% \n",
      "Full standard model test accuracy :98.11999999999999% \n",
      "Full standard model test accuracy :98.11% \n",
      "Full standard model test accuracy :98.11999999999999% \n",
      "Full standard model test accuracy :98.11999999999999% \n",
      "Full standard model test accuracy :98.11999999999999% \n",
      "Full standard model test accuracy :98.13% \n",
      "Full standard model test accuracy :98.13% \n",
      "Full standard model test accuracy :98.14% \n",
      "Full standard model test accuracy :98.13% \n",
      "Full standard model test accuracy :98.13% \n",
      "Full standard model test accuracy :98.14% \n",
      "Full standard model test accuracy :98.14% \n",
      "Full standard model test accuracy :98.15% \n",
      "Full standard model test accuracy :98.15% \n",
      "Full standard model test accuracy :98.15% \n",
      "Full standard model test accuracy :98.16% \n",
      "Full standard model test accuracy :98.16% \n",
      "Full standard model test accuracy :98.17% \n",
      "Full standard model test accuracy :98.17% \n",
      "Full standard model test accuracy :98.18% \n",
      "Full standard model test accuracy :98.18% \n",
      "Full standard model test accuracy :98.18% \n",
      "Full standard model test accuracy :98.19% \n",
      "Full standard model test accuracy :98.19% \n",
      "Full standard model test accuracy :98.2% \n",
      "Full standard model test accuracy :98.2% \n",
      "Full standard model test accuracy :98.2% \n",
      "Full standard model test accuracy :98.21% \n",
      "Full standard model test accuracy :98.21% \n",
      "Full standard model test accuracy :98.22% \n",
      "Full standard model test accuracy :98.22% \n",
      "Full standard model test accuracy :98.22% \n",
      "Full standard model test accuracy :98.22999999999999% \n",
      "Full standard model test accuracy :98.22999999999999% \n",
      "Full standard model test accuracy :98.24000000000001% \n",
      "Full standard model test accuracy :98.24000000000001% \n",
      "Full standard model test accuracy :98.22999999999999% \n",
      "Full standard model test accuracy :98.22999999999999% \n",
      "Full standard model test accuracy :98.24000000000001% \n",
      "Full standard model test accuracy :98.24000000000001% \n",
      "Full standard model test accuracy :98.25% \n",
      "Full standard model test accuracy :98.25% \n",
      "Full standard model test accuracy :98.25% \n",
      "Full standard model test accuracy :98.26% \n",
      "Full standard model test accuracy :98.26% \n",
      "Full standard model test accuracy :98.26% \n",
      "Full standard model test accuracy :98.27% \n",
      "Full standard model test accuracy :98.27% \n",
      "Full standard model test accuracy :98.28% \n",
      "Full standard model test accuracy :98.28% \n",
      "Full standard model test accuracy :98.28% \n",
      "Full standard model test accuracy :98.29% \n",
      "Full standard model test accuracy :98.29% \n",
      "Full standard model test accuracy :98.29% \n",
      "Full standard model test accuracy :98.3% \n",
      "Full standard model test accuracy :98.3% \n",
      "Full standard model test accuracy :98.29% \n",
      "Full standard model test accuracy :98.3% \n",
      "Full standard model test accuracy :98.3% \n",
      "Full standard model test accuracy :98.3% \n",
      "Full standard model test accuracy :98.31% \n",
      "Full standard model test accuracy :98.31% \n",
      "Full standard model test accuracy :98.31% \n",
      "Full standard model test accuracy :98.32% \n",
      "Full standard model test accuracy :98.32% \n",
      "Full standard model test accuracy :98.32% \n",
      "Full standard model test accuracy :98.33% \n",
      "Full standard model test accuracy :98.33% \n",
      "Full standard model test accuracy :98.33% \n",
      "Full standard model test accuracy :98.34% \n",
      "Full standard model test accuracy :98.34% \n",
      "Full standard model test accuracy :98.34% \n",
      "Full standard model test accuracy :98.35000000000001% \n",
      "Full standard model test accuracy :98.35000000000001% \n",
      "Full standard model test accuracy :98.35000000000001% \n",
      "Full standard model test accuracy :98.36% \n",
      "Full standard model test accuracy :98.36% \n",
      "Full standard model test accuracy :98.36% \n",
      "Full standard model test accuracy :98.37% \n",
      "Full standard model test accuracy :98.37% \n",
      "Full standard model test accuracy :98.37% \n",
      "Full standard model test accuracy :98.38% \n",
      "Full standard model test accuracy :98.38% \n",
      "Full standard model test accuracy :98.38% \n",
      "Full standard model test accuracy :98.39% \n",
      "Full standard model test accuracy :98.39% \n",
      "Full standard model test accuracy :98.39% \n",
      "Full standard model test accuracy :98.4% \n",
      "Full standard model test accuracy :98.39% \n",
      "Full standard model test accuracy :98.39% \n",
      "Full standard model test accuracy :98.38% \n",
      "Full standard model test accuracy :98.39% \n",
      "Full standard model test accuracy :98.39% \n",
      "Full standard model test accuracy :98.39% \n",
      "Full standard model test accuracy :98.39% \n",
      "Full standard model test accuracy :98.4% \n",
      "Full standard model test accuracy :98.4% \n",
      "Full standard model test accuracy :98.4% \n",
      "Full standard model test accuracy :98.41% \n",
      "Full standard model test accuracy :98.41% \n",
      "Full standard model test accuracy :98.41% \n",
      "Full standard model test accuracy :98.42% \n",
      "Full standard model test accuracy :98.42% \n",
      "Full standard model test accuracy :98.42% \n",
      "Full standard model test accuracy :98.42999999999999% \n",
      "Full standard model test accuracy :98.42999999999999% \n",
      "Full standard model test accuracy :98.42999999999999% \n",
      "Full standard model test accuracy :98.42999999999999% \n",
      "Full standard model test accuracy :98.44000000000001% \n",
      "Full standard model test accuracy :98.44000000000001% \n",
      "Full standard model test accuracy :98.42999999999999% \n",
      "Full standard model test accuracy :98.42999999999999% \n",
      "Full standard model test accuracy :98.44000000000001% \n",
      "Full standard model test accuracy :98.44000000000001% \n",
      "Full standard model test accuracy :98.44000000000001% \n",
      "Full standard model test accuracy :98.45% \n",
      "Full standard model test accuracy :98.45% \n",
      "Full standard model test accuracy :98.44000000000001% \n",
      "Full standard model test accuracy :98.44000000000001% \n",
      "Full standard model test accuracy :98.45% \n",
      "Full standard model test accuracy :98.45% \n",
      "Full standard model test accuracy :98.45% \n",
      "Full standard model test accuracy :98.44000000000001% \n",
      "Full standard model test accuracy :98.45% \n",
      "Full standard model test accuracy :98.44000000000001% \n",
      "Full standard model test accuracy :98.44000000000001% \n",
      "Full standard model test accuracy :98.44000000000001% \n",
      "Full standard model test accuracy :98.45% \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full standard model test accuracy :98.45% \n",
      "Full standard model test accuracy :98.45% \n",
      "Full standard model test accuracy :98.45% \n",
      "Full standard model test accuracy :98.46000000000001% \n",
      "Full standard model test accuracy :98.46000000000001% \n",
      "Full standard model test accuracy :98.46000000000001% \n",
      "Full standard model test accuracy :98.47% \n",
      "Full standard model test accuracy :98.47% \n",
      "Full standard model test accuracy :98.47% \n",
      "Full standard model test accuracy :98.47% \n",
      "Full standard model test accuracy :98.48% \n",
      "Full standard model test accuracy :98.48% \n",
      "Full standard model test accuracy :98.48% \n",
      "Full standard model test accuracy :98.49% \n",
      "Full standard model test accuracy :98.49% \n",
      "Full standard model test accuracy :98.49% \n",
      "Full standard model test accuracy :98.49% \n",
      "Full standard model test accuracy :98.5% \n",
      "Full standard model test accuracy :98.5% \n",
      "Full standard model test accuracy :98.5% \n",
      "Full standard model test accuracy :98.49% \n",
      "Full standard model test accuracy :98.48% \n",
      "Full standard model test accuracy :98.49% \n",
      "Full standard model test accuracy :98.49% \n",
      "Full standard model test accuracy :98.49% \n",
      "Full standard model test accuracy :98.5% \n",
      "Full standard model test accuracy :98.5% \n",
      "Full standard model test accuracy :98.5% \n",
      "Full standard model test accuracy :98.5% \n",
      "Full standard model test accuracy :98.50999999999999% \n",
      "Full standard model test accuracy :98.50999999999999% \n",
      "Full standard model test accuracy :98.50999999999999% \n",
      "Full standard model test accuracy :98.50999999999999% \n",
      "Full standard model test accuracy :98.52% \n",
      "Full standard model test accuracy :98.52% \n",
      "Full standard model test accuracy :98.52% \n",
      "Full standard model test accuracy :98.52% \n",
      "Full standard model test accuracy :98.53% \n",
      "Full standard model test accuracy :98.53% \n",
      "Full standard model test accuracy :98.53% \n",
      "Full standard model test accuracy :98.53% \n",
      "Full standard model test accuracy :98.54% \n",
      "Full standard model test accuracy :98.54% \n",
      "Full standard model test accuracy :98.54% \n",
      "Full standard model test accuracy :98.54% \n",
      "Full standard model test accuracy :98.55000000000001% \n",
      "Full standard model test accuracy :98.55000000000001% \n",
      "Full standard model test accuracy :98.55000000000001% \n",
      "Full standard model test accuracy :98.55000000000001% \n",
      "Full standard model test accuracy :98.56% \n",
      "Full standard model test accuracy :98.56% \n",
      "Full standard model test accuracy :98.56% \n",
      "Full standard model test accuracy :98.55000000000001% \n",
      "Full standard model test accuracy :98.56% \n",
      "Full standard model test accuracy :98.56% \n",
      "Full standard model test accuracy :98.56% \n",
      "Full standard model test accuracy :98.56% \n",
      "Full standard model test accuracy :98.56% \n",
      "Full standard model test accuracy :98.57000000000001% \n",
      "Full standard model test accuracy :98.56% \n",
      "Full standard model test accuracy :98.56% \n",
      "Full standard model test accuracy :98.54% \n",
      "Full standard model test accuracy :98.54% \n",
      "Full standard model test accuracy :98.52% \n",
      "Full standard model test accuracy :98.52% \n",
      "Full standard model test accuracy :98.52% \n",
      "Full standard model test accuracy :98.52% \n",
      "Full standard model test accuracy :98.52% \n",
      "Full standard model test accuracy :98.52% \n",
      "Full standard model test accuracy :98.52% \n",
      "Full standard model test accuracy :98.52% \n",
      "Full standard model test accuracy :98.50999999999999% \n",
      "Full standard model test accuracy :98.50999999999999% \n",
      "Full standard model test accuracy :98.5% \n",
      "Full standard model test accuracy :98.5% \n",
      "Full standard model test accuracy :98.50999999999999% \n",
      "Full standard model test accuracy :98.5% \n",
      "Full standard model test accuracy :98.5% \n",
      "Full standard model test accuracy :98.5% \n",
      "Full standard model test accuracy :98.50999999999999% \n",
      "Full standard model test accuracy :98.50999999999999% \n",
      "Full standard model test accuracy :98.50999999999999% \n",
      "elapsed time for symbolic inference: 1134.1253881454468\n"
     ]
    }
   ],
   "source": [
    "# DietCNN HyperParameters - 3 main \n",
    "# 1. Image  and all activation symbols \n",
    "# 2 & 3. Symbols for CONV and FC layers dictionary \n",
    "\n",
    "index = faiss.read_index(\"./kmeans_mnist_fullnet_k1_s1_c128_faiss_v10.index\")\n",
    "#n_clusters=512\n",
    "n_clusters=128\n",
    "\n",
    "# using a single pixel patch as of now\n",
    "patch_size = (1, 1)\n",
    "patch_stride = 1\n",
    "\n",
    "# this is the reverse dictionary - symbol to patch \n",
    "centroid_lut = index.reconstruct_n(0, n_clusters)\n",
    "\n",
    "# Pre-trained DietCNN model\n",
    "pretrained_model = \"./best_lenet_full.pt\"\n",
    "\n",
    "# Load the standard model\n",
    "net = CNN_LeNet()\n",
    "net.load_state_dict(torch.load(pretrained_model))\n",
    "state_dict = torch.load(pretrained_model)\n",
    "\n",
    "\n",
    "# Extract the filters\n",
    "c1_filter = net.conv1.weight.data.clone()\n",
    "c1_bias = net.conv1.bias.clone()\n",
    "c2_filter = net.conv2.weight.data.clone()\n",
    "c2_bias = net.conv2.bias.clone()\n",
    "\n",
    "f1_filter = net.fc1.weight.data.clone()\n",
    "f2_filter = net.fc2.weight.data.clone()\n",
    "f3_filter = net.fc3.weight.data.clone()\n",
    "\n",
    "# Load the CONV and FC dictionaries and the LUT that are created already\n",
    "import pickle\n",
    "conv_patch_size = (1, 1)\n",
    "n_cluster_conv_filters = 64\n",
    "n_cluster_fc_filters = 128\n",
    "#n_cluster_fc_filters = 256\n",
    "conv_stride = 1\n",
    "with open(\"mnist_conv_flt_full.index\", \"rb\") as f:\n",
    "    filter_index_conv = pickle.load(f)\n",
    "with open(\"mnist_fc_flt_full.index\", \"rb\") as f:\n",
    "    filter_index_fc = pickle.load(f)\n",
    "fc_lut = np.genfromtxt('./mnist_fc_lut_full.txt', delimiter=',',dtype=np.int16) \n",
    "conv_lut = np.genfromtxt('./mnist_conv_lut_full.txt', delimiter=',',dtype=np.int16) \n",
    "add_lut = np.genfromtxt('./mnist_add_lut_full.txt', delimiter=',',dtype=np.int16) \n",
    "relu_lut = np.genfromtxt('./mnist_relu_lut_full.txt', delimiter=',',dtype=np.int16)\n",
    "c1blut = np.genfromtxt('./mnist_c1_bias_lut_full.txt', delimiter=',',dtype=np.int16)\n",
    "c2blut = np.genfromtxt('./mnist_c2_bias_lut_full.txt', delimiter=',',dtype=np.int16)\n",
    "f1blut = np.genfromtxt('./mnist_f1_bias_lut_full.txt', delimiter=',',dtype=np.int16)\n",
    "f2blut = np.genfromtxt('./mnist_f2_bias_lut_full.txt', delimiter=',',dtype=np.int16)\n",
    "\n",
    "# this is the creation of symbolic model.\n",
    "# All these steps are need in the desktop implementation to sync with PyTorch inference\n",
    "# For FPGA implementation the DietCNN models are quite simple \n",
    "\n",
    "netsym = lenet_sym(net,state_dict, filter_index_conv, filter_index_fc, conv_lut, fc_lut, add_lut, c1blut,c2blut, f1blut,f2blut,relu_lut, n_clusters, index, centroid_lut, patch_size, patch_stride, False)\n",
    "netsym.eval()\n",
    "start_t = time.time()  \n",
    "acc = test_fullsym_acc(netsym, None, testloader, bs, False, False, 1)\n",
    "end = time.time()\n",
    "print(\"elapsed time for symbolic inference:\", end - start_t) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
